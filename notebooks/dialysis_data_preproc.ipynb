{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.idle": "2021-02-26T00:55:03.680232Z",
     "shell.execute_reply": "2021-02-26T00:55:03.679685Z",
     "shell.execute_reply.started": "2021-02-26T00:55:03.443273Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_dir = \"/home/davina/Private/dialysis-data\"\n",
    "static_features = [\n",
    "    \"Allergies_19-000093_10082020.txt\",\n",
    "    \"Patient_Demographics_19-000093_10082020.txt\",\n",
    "    \"Social_History_19-000093_10082020.txt\",\n",
    "]\n",
    "encounters = [\n",
    "    \"enc_19-000093_10082020.txt\",\n",
    "    \"Encounter_Diagnoses_19-000093_10082020.txt\",\n",
    "    \"Encounters_19-000093_10082020.txt\",\n",
    "    \"Family_History_19-000093_10082020.txt\",\n",
    "    \"Flowsheet_Vitals_19-000093_10082020.txt\",\n",
    "    \"Hospital_Unit_Transfers_19-000093_10082020.txt\",\n",
    "#     \"Labs_19-000093_10082020.txt\",\n",
    "    \"Medications_19-000093_10082020.txt\",\n",
    "    \"problem_list_diagnoses_19-000093_10082020.txt\",\n",
    "    \"Problem_Lists_19-000093_10082020.txt\",\n",
    "#     \"Procedures_19-000093_10082020.txt\",\n",
    "]\n",
    "provider_mapping_file = \"providers_19-000093_10082020.txt\"\n",
    "outcome_file = \"CRRT Deidentified 2017-2019.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-26T00:55:03.681170Z",
     "iopub.status.busy": "2021-02-26T00:55:03.681015Z",
     "iopub.status.idle": "2021-02-26T00:55:03.692848Z",
     "shell.execute_reply": "2021-02-26T00:55:03.692328Z",
     "shell.execute_reply.started": "2021-02-26T00:55:03.681154Z"
    }
   },
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "from typing import List\n",
    "\n",
    "def read_files_and_combine(files: List[str]):\n",
    "    dfs = []\n",
    "\n",
    "    for file in files:\n",
    "        try:\n",
    "            dfs.append(pd.read_csv(f\"{data_dir}/{file}\"))\n",
    "        except:\n",
    "            print(f\"Unexpected encoding in {file}\")\n",
    "            default_guess = \"cp1252\"\n",
    "            import os\n",
    "            # get file encoding using file -i and extracting name with sed\n",
    "            # ref: https://unix.stackexchange.com/a/393949\n",
    "            # -n: don't print unless we say. s/ search, .* match any, charset=, // remove text up until after =, print remaining\n",
    "            command = f\"file -i {data_dir}/{file} | sed -n 's/.*charset=//p'\"\n",
    "            # [:-1] ignore newline\n",
    "            encoding = os.popen(command).read()[:-1]\n",
    "            print(f\"Encoding was {encoding} instead of assumed utf-8.\")\n",
    "            if encoding == \"unknown-8bit\":\n",
    "                print(f\"Assuming {default_guess}...\")\n",
    "                dfs.append(pd.read_csv(f\"{data_dir}/{file}\",  encoding=default_guess))\n",
    "            else:\n",
    "                dfs.append(pd.read_csv(f\"{data_dir}/{file}\",  encoding=encoding))\n",
    "    combined = reduce(lambda df1, df2: pd.merge(df1, df2, on=\"IP_PATIENT_ID\", how=\"inner\"), dfs)\n",
    "    return combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_df = read_files_and_combine(static_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-26T00:55:03.704638Z",
     "iopub.status.busy": "2021-02-26T00:55:03.704499Z",
     "iopub.status.idle": "2021-02-26T00:55:03.710555Z",
     "shell.execute_reply": "2021-02-26T00:55:03.710134Z",
     "shell.execute_reply.started": "2021-02-26T00:55:03.704624Z"
    }
   },
   "outputs": [],
   "source": [
    "# map provider id to type\n",
    "provider_mapping = pd.read_csv(f\"{data_dir}/{provider_mapping_file}\")\n",
    "provider_mapping = dict(zip(provider_mapping[\"IP_PROVIDER_ID\"], provider_mapping[\"PROVIDER_TYPE\"]))\n",
    "static_df[\"PCP_IP_PROVIDER_ID\"] = static_df[\"PCP_IP_PROVIDER_ID\"].map(provider_mapping)\n",
    "static_df.rename(columns={\"PCP_IP_PROVIDER_ID\" : \"PCP_PROVIDER_TYPE\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-26T00:55:03.711271Z",
     "iopub.status.busy": "2021-02-26T00:55:03.711134Z",
     "iopub.status.idle": "2021-02-26T00:55:03.746401Z",
     "shell.execute_reply": "2021-02-26T00:55:03.745960Z",
     "shell.execute_reply.started": "2021-02-26T00:55:03.711257Z"
    }
   },
   "outputs": [],
   "source": [
    "static_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-26T00:55:03.747112Z",
     "iopub.status.busy": "2021-02-26T00:55:03.746959Z",
     "iopub.status.idle": "2021-02-26T00:55:03.750819Z",
     "shell.execute_reply": "2021-02-26T00:55:03.750389Z",
     "shell.execute_reply.started": "2021-02-26T00:55:03.747097Z"
    }
   },
   "outputs": [],
   "source": [
    "static_df[\"IP_PATIENT_ID\"].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LONGITUDINAL FEATURES\n",
    "\n",
    "- encounters: basic info about each encounter\n",
    "- diagnoses: combine all diagnoses for a given patient across all encounters then one hot encode for the top 10 most common diagnoses\n",
    "- history: ??\n",
    "- flowsheet vitals: aggregatie across each type of vital sign (min, max, mean, etc)\n",
    "- hospital unit transfers: i think we shouldn't use this for now\n",
    "- labs: aggregate across each continuous lab (min, max, etc).\n",
    "    - maybe look at all the labs that are not continuous values and decide what to do with those\n",
    "- medications: treat like diagnoses\n",
    "- procedures: treat like diagnoses\n",
    "    - use code or name, just keep mapping intact\n",
    "- how is problem_list_diagnoses different from problem_lists and dignoses?\n",
    "\n",
    "We're going to have to do feature selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import skew\n",
    "\n",
    "aggregate_functions = [min, max, np.mean, np.std, skew, len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: continue\n",
    "longitudinal_df = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load + Preproc Outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-26T00:55:03.751523Z",
     "iopub.status.busy": "2021-02-26T00:55:03.751344Z",
     "iopub.status.idle": "2021-02-26T00:55:03.769652Z",
     "shell.execute_reply": "2021-02-26T00:55:03.769206Z",
     "shell.execute_reply.started": "2021-02-26T00:55:03.751507Z"
    }
   },
   "outputs": [],
   "source": [
    "# get first sheet only\n",
    "outcomes = pd.read_csv(f\"{data_dir}/{outcome_file}\")\n",
    "\n",
    "# Exclude pediatric data\n",
    "exclude_peds = outcomes[\"Hospital name\"] != \"UCLA MEDICAL CENTER- PEDIATRICS\"\n",
    "outcomes = outcomes[exclude_peds]\n",
    "\n",
    "outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate Outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-26T00:55:12.288110Z",
     "iopub.status.busy": "2021-02-26T00:55:12.287524Z",
     "iopub.status.idle": "2021-02-26T00:55:12.303998Z",
     "shell.execute_reply": "2021-02-26T00:55:12.303210Z",
     "shell.execute_reply.started": "2021-02-26T00:55:12.288058Z"
    }
   },
   "outputs": [],
   "source": [
    "positive_outcomes = [\"Recov. renal funct.\", \"Transitioned to HD\"]\n",
    "negative_outcomes = [\"Palliative Care\", \"Expired \"] \n",
    "outcome_cols = positive_outcomes + negative_outcomes\n",
    "outcomes[outcome_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-26T00:55:12.999013Z",
     "iopub.status.busy": "2021-02-26T00:55:12.998506Z",
     "iopub.status.idle": "2021-02-26T00:55:13.020869Z",
     "shell.execute_reply": "2021-02-26T00:55:13.020184Z",
     "shell.execute_reply.started": "2021-02-26T00:55:12.998964Z"
    }
   },
   "outputs": [],
   "source": [
    "# Each row should have exactly 1 1.0 value (one-hot of the 4 cols)\n",
    "bad_rows = outcomes[outcome_cols].fillna(0).sum(axis=1) == 0\n",
    "outcomes[bad_rows]\n",
    "## TODO: Should i drop the bad row?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct outcome feature (recommend dialysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-26T00:55:14.009504Z",
     "iopub.status.busy": "2021-02-26T00:55:14.008981Z",
     "iopub.status.idle": "2021-02-26T00:55:14.022150Z",
     "shell.execute_reply": "2021-02-26T00:55:14.020662Z",
     "shell.execute_reply.started": "2021-02-26T00:55:14.009455Z"
    }
   },
   "outputs": [],
   "source": [
    "recommend_dialysis = (outcomes[\"Recov. renal funct.\"] == 1) | (outcomes[\"Transitioned to HD\"] == 1)\n",
    "outcomes[\"recommend_dialysis\"] =  recommend_dialysis.astype(int)\n",
    "\n",
    "# To combine with features\n",
    "outcome_df = outcomes[[\"IP_PATIENT_ID\", \"recommend_dialysis\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-26T00:55:53.783151Z",
     "iopub.status.busy": "2021-02-26T00:55:53.782800Z",
     "iopub.status.idle": "2021-02-26T00:55:53.789186Z",
     "shell.execute_reply": "2021-02-26T00:55:53.788222Z",
     "shell.execute_reply.started": "2021-02-26T00:55:53.783122Z"
    }
   },
   "outputs": [],
   "source": [
    "sum(outcome_df[\"recommend_dialysis\"])/len(outcome_df) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge features with outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-26T00:55:15.103707Z",
     "iopub.status.busy": "2021-02-26T00:55:15.103071Z",
     "iopub.status.idle": "2021-02-26T00:55:15.147605Z",
     "shell.execute_reply": "2021-02-26T00:55:15.147003Z",
     "shell.execute_reply.started": "2021-02-26T00:55:15.103654Z"
    }
   },
   "outputs": [],
   "source": [
    "# features_with_outcomes = pd.merge(combined, outcome_df, on=\"IP_PATIENT_ID\", how=\"inner\")\n",
    "features_with_outcomes = reduce(lambda df1, df2: pd.merge(df1, df2, on=\"IP_PATIENT_ID\", how=\"inner\"),\n",
    "                                [static_df, longitudinal_df, outcome_df])\n",
    "features_with_outcomes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit ('crrt': conda)",
   "name": "python394jvsc74a57bd04c370c389331391116e354fd9083bcd4852b78f207c9080c8282e65bde3a44b9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
