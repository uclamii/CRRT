{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.idle": "2021-02-26T00:55:03.680232Z",
     "shell.execute_reply": "2021-02-26T00:55:03.679685Z",
     "shell.execute_reply.started": "2021-02-26T00:55:03.443273Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_dir = \"/home/davina/Private/dialysis-data\"\n",
    "static_features = [\n",
    "    \"Allergies_19-000093_10082020.txt\",\n",
    "    \"Patient_Demographics_19-000093_10082020.txt\",\n",
    "    \"Social_History_19-000093_10082020.txt\",\n",
    "]\n",
    "encounters = [\n",
    "    \"enc_19-000093_10082020.txt\",\n",
    "    \"Encounter_Diagnoses_19-000093_10082020.txt\",\n",
    "    \"Encounters_19-000093_10082020.txt\",\n",
    "    \"Family_History_19-000093_10082020.txt\",\n",
    "    \"Flowsheet_Vitals_19-000093_10082020.txt\",\n",
    "    \"Hospital_Unit_Transfers_19-000093_10082020.txt\",\n",
    "#     \"Labs_19-000093_10082020.txt\",\n",
    "    \"Medications_19-000093_10082020.txt\",\n",
    "    \"problem_list_diagnoses_19-000093_10082020.txt\",\n",
    "    \"Problem_Lists_19-000093_10082020.txt\",\n",
    "#     \"Procedures_19-000093_10082020.txt\",\n",
    "]\n",
    "provider_mapping_file = \"providers_19-000093_10082020.txt\"\n",
    "outcome_file = \"CRRT Deidentified 2017-2019.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-26T00:55:03.681170Z",
     "iopub.status.busy": "2021-02-26T00:55:03.681015Z",
     "iopub.status.idle": "2021-02-26T00:55:03.692848Z",
     "shell.execute_reply": "2021-02-26T00:55:03.692328Z",
     "shell.execute_reply.started": "2021-02-26T00:55:03.681154Z"
    }
   },
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "from typing import List\n",
    "\n",
    "def read_files_and_combine(files: List[str]):\n",
    "    dfs = []\n",
    "\n",
    "    for file in files:\n",
    "        try:\n",
    "            dfs.append(pd.read_csv(f\"{data_dir}/{file}\"))\n",
    "        except:\n",
    "            print(f\"Unexpected encoding in {file}\")\n",
    "            default_guess = \"cp1252\"\n",
    "            import os\n",
    "            # get file encoding using file -i and extracting name with sed\n",
    "            # ref: https://unix.stackexchange.com/a/393949\n",
    "            # -n: don't print unless we say. s/ search, .* match any, charset=, // remove text up until after =, print remaining\n",
    "            command = f\"file -i {data_dir}/{file} | sed -n 's/.*charset=//p'\"\n",
    "            # [:-1] ignore newline\n",
    "            encoding = os.popen(command).read()[:-1]\n",
    "            print(f\"Encoding was {encoding} instead of assumed utf-8.\")\n",
    "            if encoding == \"unknown-8bit\":\n",
    "                print(f\"Assuming {default_guess}...\")\n",
    "                dfs.append(pd.read_csv(f\"{data_dir}/{file}\",  encoding=default_guess))\n",
    "            else:\n",
    "                dfs.append(pd.read_csv(f\"{data_dir}/{file}\",  encoding=encoding))\n",
    "    combined = reduce(lambda df1, df2: pd.merge(df1, df2, on=\"IP_PATIENT_ID\", how=\"inner\"), dfs)\n",
    "    return combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_df = read_files_and_combine(static_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-26T00:55:03.704638Z",
     "iopub.status.busy": "2021-02-26T00:55:03.704499Z",
     "iopub.status.idle": "2021-02-26T00:55:03.710555Z",
     "shell.execute_reply": "2021-02-26T00:55:03.710134Z",
     "shell.execute_reply.started": "2021-02-26T00:55:03.704624Z"
    }
   },
   "outputs": [],
   "source": [
    "# map provider id to type\n",
    "provider_mapping = pd.read_csv(f\"{data_dir}/{provider_mapping_file}\")\n",
    "provider_mapping = dict(zip(provider_mapping[\"IP_PROVIDER_ID\"], provider_mapping[\"PROVIDER_TYPE\"]))\n",
    "static_df[\"PCP_IP_PROVIDER_ID\"] = static_df[\"PCP_IP_PROVIDER_ID\"].map(provider_mapping)\n",
    "static_df.rename(columns={\"PCP_IP_PROVIDER_ID\" : \"PCP_PROVIDER_TYPE\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-26T00:55:03.711271Z",
     "iopub.status.busy": "2021-02-26T00:55:03.711134Z",
     "iopub.status.idle": "2021-02-26T00:55:03.746401Z",
     "shell.execute_reply": "2021-02-26T00:55:03.745960Z",
     "shell.execute_reply.started": "2021-02-26T00:55:03.711257Z"
    }
   },
   "outputs": [],
   "source": [
    "static_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-26T00:55:03.747112Z",
     "iopub.status.busy": "2021-02-26T00:55:03.746959Z",
     "iopub.status.idle": "2021-02-26T00:55:03.750819Z",
     "shell.execute_reply": "2021-02-26T00:55:03.750389Z",
     "shell.execute_reply.started": "2021-02-26T00:55:03.747097Z"
    }
   },
   "outputs": [],
   "source": [
    "static_df[\"IP_PATIENT_ID\"].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LONGITUDINAL FEATURES\n",
    "\n",
    "- encounters: basic info about each encounter\n",
    "- diagnoses: combine all diagnoses for a given patient across all encounters then one hot encode for the top 10 most common diagnoses\n",
    "- history: ??\n",
    "- flowsheet vitals: aggregatie across each type of vital sign (min, max, mean, etc)\n",
    "- hospital unit transfers: i think we shouldn't use this for now\n",
    "- labs: aggregate across each continuous lab (min, max, etc).\n",
    "    - maybe look at all the labs that are not continuous values and decide what to do with those\n",
    "- medications: treat like diagnoses\n",
    "- procedures: treat like diagnoses\n",
    "    - use code or name, just keep mapping intact\n",
    "- how is problem_list_diagnoses different from problem_lists and dignoses?\n",
    "\n",
    "We're going to have to do feature selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import skew\n",
    "\n",
    "aggregate_functions = [min, max, np.mean, np.std, skew, len]\n",
    "longitudinal_df = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diagnoses\n",
    "How do we want to deal with icd9 vs icd10?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dx_df = read_files_and_combine([\"Encounter_Diagnoses_19-000093_10082020.txt\"])\n",
    "# Top N codes\n",
    "top_n = 15\n",
    "dx_df[dx_df[\"ICD_TYPE\"] == 10].groupby(\"ICD_CODE\").size().sort_values(ascending=False)[:top_n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ICD9 VS ICD10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "icd10_n = (dx_df['ICD_TYPE'] == 10).sum()\n",
    "icd9_n = (dx_df['ICD_TYPE'] == 9).sum()\n",
    "f\"ICD 10: {icd10_n}, ICD 9: {icd9_n}, ratio of 10:9: {icd10_n / icd9_n}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Date ranges for ICD9 codes (min and max)\n",
    "icd9_dx_dates = pd.to_datetime(dx_df[dx_df[\"ICD_TYPE\"] == 9][\"DIAGNOSIS_DATE\"])\n",
    "f\"min date: {icd9_dx_dates.min()}, max_date: {icd9_dx_dates.max()}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ICD9 is 2013 - 2015, outcomes are 2018-2019, so we will ignore all ICD9 codes and use HCUP to map ICD10 codes to CSSR categories to reduce the number of categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ICD10 to CSSR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hcuppy.ccs import CCSEngine\n",
    "ce = CCSEngine(mode=\"dx\")\n",
    "# convert icd10 to ccs\n",
    "dx_df[\"CCS_CODE\"] = dx_df[dx_df[\"ICD_TYPE\"] == 10][\"ICD_CODE\"].apply(lambda icd_code: ce.get_ccs(icd_code)[\"ccs\"])\n",
    "dx_df.groupby(\"CCS_CODE\").size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vitals\n",
    "\n",
    "These looks a little strange right now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vitals_df = read_files_and_combine([\"Flowsheet_Vitals_19-000093_10082020.txt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_size = vitals_df.shape[0]\n",
    "\n",
    "# drop duplicates for the same patient for the same vital (taken at same time indicates duplicate)\n",
    "vitals_df = vitals_df.drop_duplicates(subset=[\"IP_PATIENT_ID\", \"VITAL_SIGN_TYPE\", \"VITAL_SIGN_TAKEN_TIME\"])\n",
    "f\"Dropped {old_size - vitals_df.shape[0]} rows that were duplicates.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split BP into SBP and DBP\n",
    "vitals_df[\"VITAL_SIGN_TYPE\"].replace({\"BP\": \"SBP/DBP\"}, inplace=True)\n",
    "explode_cols = [\"VITAL_SIGN_VALUE\", \"VITAL_SIGN_TYPE\"]\n",
    "def try_split_col(col: pd.Series):\n",
    "    # Split col with \"/\" in it (only BP values and name) from explode_cols\n",
    "    try:\n",
    "        return col.str.split(\"/\").explode()\n",
    "    except:\n",
    "        return col\n",
    "\n",
    "# Ref: https://stackoverflow.com/a/57122617/1888794\n",
    "# don't explode the columsn you set index to, explode the rest via apply, reset everything to normal\n",
    "vitals_df = (vitals_df.set_index(list(vitals_df.columns.difference(explode_cols)))\n",
    "                    .apply(try_split_col)\n",
    "                    .reset_index()\n",
    "                    .reindex(vitals_df.columns, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these vitals are not float point numbers, we want to ignore them and then convert the vitals to float to aggregate\n",
    "ignore_vitals = [\"O2 Device\"]\n",
    "ignore_mask = ~vitals_df[\"VITAL_SIGN_TYPE\"].isin(ignore_vitals)\n",
    "vitals_df = vitals_df[ignore_mask]\n",
    "# convert to float\n",
    "vitals_df[\"VITAL_SIGN_VALUE\"] = vitals_df[\"VITAL_SIGN_VALUE\"].astype(float)\n",
    "# Aggregate\n",
    "vitals_df.groupby([\"IP_PATIENT_ID\", \"VITAL_SIGN_TYPE\"]).agg({\"VITAL_SIGN_VALUE\": aggregate_functions})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Medications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rx_df = read_files_and_combine([\"Medications_19-000093_10082020.txt\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rx_df.groupby(\"GENERIC_NAME\").size().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labs: TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labs_df = read_files_and_combine([\"Labs_19-000093_10082020.txt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "labs_df.groupby([\"IP_PATIENT_ID\", \"PROC_ID\"]).agg({\"RESULTS\": aggregate_functions})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problems_df = read_files_and_combine([\"Problem_Lists_19-000093_10082020.txt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problems_df.groupby(\"problem_status\").size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Procedures\n",
    "TODO: We need to know if ICD9, ICD10, or APT Code?\n",
    "We can otherwise use hcuppy to convert procedures: `hcuppy.prcls` procedure class for those that work otherwise ignore or drop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "procedure_df = read_files_and_combine([\"Procedures_19-000093_10082020.txt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "procedure_df.groupby(\"PROC_CODE\").size().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load + Preproc Outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-26T00:55:03.751523Z",
     "iopub.status.busy": "2021-02-26T00:55:03.751344Z",
     "iopub.status.idle": "2021-02-26T00:55:03.769652Z",
     "shell.execute_reply": "2021-02-26T00:55:03.769206Z",
     "shell.execute_reply.started": "2021-02-26T00:55:03.751507Z"
    }
   },
   "outputs": [],
   "source": [
    "# get first sheet only\n",
    "outcomes = pd.read_csv(f\"{data_dir}/{outcome_file}\")\n",
    "\n",
    "# Exclude pediatric data\n",
    "exclude_peds = outcomes[\"Hospital name\"] != \"UCLA MEDICAL CENTER- PEDIATRICS\"\n",
    "outcomes = outcomes[exclude_peds]\n",
    "\n",
    "# TODO: include CRRT Total Days as predictive feature\n",
    "\n",
    "outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Date range for outcomes\n",
    "outcome_end_date = pd.to_datetime(outcomes[\"End Date\"])\n",
    "f\"min date: {outcome_end_date.min()}. max date: {outcome_end_date.max()}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate Outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-26T00:55:12.288110Z",
     "iopub.status.busy": "2021-02-26T00:55:12.287524Z",
     "iopub.status.idle": "2021-02-26T00:55:12.303998Z",
     "shell.execute_reply": "2021-02-26T00:55:12.303210Z",
     "shell.execute_reply.started": "2021-02-26T00:55:12.288058Z"
    }
   },
   "outputs": [],
   "source": [
    "positive_outcomes = [\"Recov. renal funct.\", \"Transitioned to HD\"]\n",
    "negative_outcomes = [\"Palliative Care\", \"Expired \"] \n",
    "outcome_cols = positive_outcomes + negative_outcomes\n",
    "outcomes[outcome_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-26T00:55:12.999013Z",
     "iopub.status.busy": "2021-02-26T00:55:12.998506Z",
     "iopub.status.idle": "2021-02-26T00:55:13.020869Z",
     "shell.execute_reply": "2021-02-26T00:55:13.020184Z",
     "shell.execute_reply.started": "2021-02-26T00:55:12.998964Z"
    }
   },
   "outputs": [],
   "source": [
    "# Each row should have exactly 1 1.0 value (one-hot of the 4 cols)\n",
    "bad_rows = outcomes[outcome_cols].fillna(0).sum(axis=1) == 0\n",
    "outcomes[bad_rows]\n",
    "## TODO: Should i drop the bad row?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct outcome feature (recommend dialysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-26T00:55:14.009504Z",
     "iopub.status.busy": "2021-02-26T00:55:14.008981Z",
     "iopub.status.idle": "2021-02-26T00:55:14.022150Z",
     "shell.execute_reply": "2021-02-26T00:55:14.020662Z",
     "shell.execute_reply.started": "2021-02-26T00:55:14.009455Z"
    }
   },
   "outputs": [],
   "source": [
    "recommend_dialysis = (outcomes[\"Recov. renal funct.\"] == 1) | (outcomes[\"Transitioned to HD\"] == 1)\n",
    "outcomes[\"recommend_dialysis\"] =  recommend_dialysis.astype(int)\n",
    "\n",
    "# To combine with features\n",
    "outcome_df = outcomes[[\"IP_PATIENT_ID\", \"recommend_dialysis\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-26T00:55:53.783151Z",
     "iopub.status.busy": "2021-02-26T00:55:53.782800Z",
     "iopub.status.idle": "2021-02-26T00:55:53.789186Z",
     "shell.execute_reply": "2021-02-26T00:55:53.788222Z",
     "shell.execute_reply.started": "2021-02-26T00:55:53.783122Z"
    }
   },
   "outputs": [],
   "source": [
    "sum(outcome_df[\"recommend_dialysis\"])/len(outcome_df) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge features with outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-26T00:55:15.103707Z",
     "iopub.status.busy": "2021-02-26T00:55:15.103071Z",
     "iopub.status.idle": "2021-02-26T00:55:15.147605Z",
     "shell.execute_reply": "2021-02-26T00:55:15.147003Z",
     "shell.execute_reply.started": "2021-02-26T00:55:15.103654Z"
    }
   },
   "outputs": [],
   "source": [
    "# features_with_outcomes = pd.merge(combined, outcome_df, on=\"IP_PATIENT_ID\", how=\"inner\")\n",
    "features_with_outcomes = reduce(lambda df1, df2: pd.merge(df1, df2, on=\"IP_PATIENT_ID\", how=\"inner\"),\n",
    "                                [static_df, longitudinal_df, outcome_df])\n",
    "features_with_outcomes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit ('crrt': conda)",
   "name": "python394jvsc74a57bd04c370c389331391116e354fd9083bcd4852b78f207c9080c8282e65bde3a44b9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
