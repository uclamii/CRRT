{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import mlflow.tracking\n",
    "import pandas as pd\n",
    "import pickle \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "from os import getcwd\n",
    "from os.path import join\n",
    "import ast\n",
    "from typing import Any\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "sys.path.insert(0, join(getcwd(), \"../module_code\"))\n",
    "\n",
    "import cli_utils \n",
    "import main\n",
    "\n",
    "sys.argv = [sys.argv[0]]\n",
    "cli_utils.load_cli_args(\"../options.yml\")\n",
    "args = cli_utils.init_cli_args()\n",
    "\n",
    "mlflow_path = \"C:/Users/jeffe/mlflow/mlruns\"\n",
    "client =  mlflow.tracking.MlflowClient(f\"file://{mlflow_path}\")\n",
    "\n",
    "# The id of the test run from mlflow\n",
    "ucla_cedars_run_id = \"11a8d9fe093b4e4b82f498f96c66bc7f\"\n",
    "ucla_ucla_run_id = \"92cfb3bbeddb465ca4c0c6c4ca5efadd\"\n",
    "cedars_cedars_run_id = \"513e5a5453a84031ba446b2c3d52578b\"\n",
    "cedars_ucla_run_id = \"6d13ec12e43a49789e278b0bec687d7e\"\n",
    "both_id = \"c4511a2c69ca47168063487a82b0c9c2\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tabulate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_table(id):\n",
    "    table = {}\n",
    "\n",
    "    run = client.get_run(id)\n",
    "    metrics = run.data.metrics\n",
    "    modeln = run.data.tags['modeln']\n",
    "\n",
    "    for metric_name in [\"accuracy\", \"ap\", \"auroc\", \"brier\", \"precision\", \"recall\"]:\n",
    "        table[metric_name] = {}\n",
    "        for subgroup in [\"\", \"_heart\", \"_liver\", \"_infection\"]:\n",
    "            prefix = f\"{modeln}_test{subgroup}\"\n",
    "            subgroup = \"all\" if subgroup == \"\" else subgroup\n",
    "\n",
    "            if f\"{prefix}__{metric_name}_CI_low\" in metrics:\n",
    "                ci_low = metrics[f\"{prefix}__{metric_name}_CI_low\"]\n",
    "                ci_high = metrics[f\"{prefix}__{metric_name}_CI_high\"]\n",
    "                metric = metrics[f\"{prefix}__{metric_name}\"]\n",
    "                table[metric_name][subgroup.replace(\"_\",\"\")] = f\"{metric:.2f} ({ci_low:.2f}-{ci_high:.2f})\"\n",
    "            else:\n",
    "                table[metric_name][subgroup.replace(\"_\",\"\")] = metrics[f\"{prefix}__{metric_name}\"]\n",
    "    \n",
    "    return table"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output from mlflow without CI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The id of the test run from mlflow\n",
    "ucla_cedars_run_id = \"11a8d9fe093b4e4b82f498f96c66bc7f\"\n",
    "ucla_ucla_run_id = \"92cfb3bbeddb465ca4c0c6c4ca5efadd\"\n",
    "cedars_cedars_run_id = \"513e5a5453a84031ba446b2c3d52578b\"\n",
    "cedars_ucla_run_id = \"6d13ec12e43a49789e278b0bec687d7e\"\n",
    "both_id = \"c4511a2c69ca47168063487a82b0c9c2\"\n",
    "\n",
    "table = get_table(ucla_ucla_run_id)\n",
    "print('UCLA to UCLA')\n",
    "display(pd.DataFrame(table))\n",
    "\n",
    "table = get_table(ucla_cedars_run_id)\n",
    "print('UCLA to CEDARS')\n",
    "display(pd.DataFrame(table))\n",
    "\n",
    "table = get_table(cedars_ucla_run_id)\n",
    "print('CEDARS to UCLA')\n",
    "display(pd.DataFrame(table))\n",
    "\n",
    "table = get_table(cedars_cedars_run_id)\n",
    "print('CEDARS to CEDARS')\n",
    "display(pd.DataFrame(table))\n",
    "\n",
    "table = get_table(both_id)\n",
    "print('UCLA+CEDARS to UCLA+CEDARS')\n",
    "display(pd.DataFrame(table))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output from mlflow after post-hoc with CI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The id of the post-hoc test run from mlflow with CI\n",
    "ucla_cedars_run_id = \"ce12b0e992014d30a3d0ee1d44610dc5\"\n",
    "ucla_ucla_run_id = \"125c0fb5c21f4533a45a9258822de83e\"\n",
    "cedars_cedars_run_id = \"548afa05e3ee42208c20a2557dc1800a\"\n",
    "cedars_ucla_run_id = \"a07635aa0e50492d811d0ac7d9e807ac\"\n",
    "both_id = \"7bbdb269ea9041f799fa9de7e7d34b45\"\n",
    "\n",
    "table = get_table(ucla_ucla_run_id)\n",
    "print('UCLA to UCLA')\n",
    "display(pd.DataFrame(table))\n",
    "\n",
    "table = get_table(ucla_cedars_run_id)\n",
    "print('UCLA to CEDARS')\n",
    "display(pd.DataFrame(table))\n",
    "\n",
    "table = get_table(cedars_ucla_run_id)\n",
    "print('CEDARS to UCLA')\n",
    "display(pd.DataFrame(table))\n",
    "\n",
    "table = get_table(cedars_cedars_run_id)\n",
    "print('CEDARS to CEDARS')\n",
    "display(pd.DataFrame(table))\n",
    "\n",
    "table = get_table(both_id)\n",
    "print('UCLA+CEDARS to UCLA+CEDARS')\n",
    "display(pd.DataFrame(table))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output from mlflow after post-hoc with CI, and limit 7 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The id of the post-hoc test run from mlflow with CI with limiting 7 days on CRRT\n",
    "ucla_cedars_run_id = \"5801be55809c4e3e91478d26ee0ee614\"\n",
    "ucla_ucla_run_id = \"52d929585bd84345a5007ec99e1f3185\"\n",
    "cedars_cedars_run_id = \"cf50989ed9e24cf3aefd4b6232c40ff5\"\n",
    "cedars_ucla_run_id = \"b985f4b14d9e42da85dc296ce9e64118\"\n",
    "both_id = \"e7538934abdf4977af24b114fcac83d9\"\n",
    "\n",
    "table = get_table(ucla_ucla_run_id)\n",
    "print('UCLA to UCLA')\n",
    "display(pd.DataFrame(table))\n",
    "\n",
    "table = get_table(ucla_cedars_run_id)\n",
    "print('UCLA to CEDARS')\n",
    "display(pd.DataFrame(table))\n",
    "\n",
    "table = get_table(cedars_ucla_run_id)\n",
    "print('CEDARS to UCLA')\n",
    "display(pd.DataFrame(table))\n",
    "\n",
    "table = get_table(cedars_cedars_run_id)\n",
    "print('CEDARS to CEDARS')\n",
    "display(pd.DataFrame(table))\n",
    "\n",
    "table = get_table(both_id)\n",
    "print('UCLA+CEDARS to UCLA+CEDARS')\n",
    "display(pd.DataFrame(table))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run post-hoc test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = client.get_run(cedars_ucla_run_id)\n",
    "best_run = run.data.tags['best_run_id']\n",
    "run = client.get_run(best_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reinit_param_from_string(args: ArgumentParser, param_name:str, param_val: Any) -> Any:\n",
    "    if param_val == \"None\":\n",
    "        return None\n",
    "    elif param_name in args.__dict__.keys():\n",
    "        if type(args.__dict__[param_name]) in [int, str, float]:\n",
    "            return type(args.__dict__[param_name])(param_val)\n",
    "        else:\n",
    "            return ast.literal_eval(param_val)\n",
    "    else:\n",
    "        return param_val\n",
    "\n",
    "# Update with best params and with the run id.\n",
    "best_model_path = main.get_mlflow_model_uri(run)\n",
    "dargs = vars(args)\n",
    "modeln = run.data.tags[\"modeln\"]\n",
    "\n",
    "# split the best params into the ones that should be in model_kwargs and not\n",
    "top_level_params = {}\n",
    "model_kwargs = {}\n",
    "for param_name, param_val in run.data.tags.items():\n",
    "    if param_name.startswith(modeln):\n",
    "        # exclude the rf_ if modeln is rf\n",
    "        raw_name = param_name[len(f\"{args.modeln}\") :]\n",
    "        model_kwargs[raw_name] = param_val\n",
    "    else:\n",
    "        top_level_params[param_name] = reinit_param_from_string(args, param_name, param_val)\n",
    "model_kwargs.update(run.data.params)\n",
    "\n",
    "dargs.update(\n",
    "    {\n",
    "        **top_level_params,\n",
    "        # modeln is selected outside of optuna so it wont be in params\n",
    "        \"modeln\": modeln,\n",
    "        # model_kwargs in best_trial.params but flattened out\n",
    "        \"model_kwargs\": model_kwargs,\n",
    "        \"best_run_id\": run.info.run_id,\n",
    "        \"best_model_path\": best_model_path,\n",
    "        \"stage\": \"eval\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dargs.update(\n",
    "    {\n",
    "        \"run_name\": 'post_eval',\n",
    "        \"ucla_crrt_data_dir\": \"C:/Users/jeffe/OneDrive - UCLA IT Services/UCLA/2023_Winter/Rotation/Data/UCLA\",\n",
    "        \"ucla_control_data_dir\": \"C:/Users/jeffe/OneDrive - UCLA IT Services/UCLA/2023_Winter/Rotation/Data/UCLA/Controls\",\n",
    "        \"cedars_crrt_data_dir\": \"C:/Users/jeffe/OneDrive - UCLA IT Services/UCLA/2023_Winter/Rotation/Data/Cedars\",\n",
    "        \"best_model_path\": args.best_model_path.replace('/var/snap/amazon-ssm-agent/6312/dev/','C:/Users/jeffe/'),\n",
    "        \"local_log_path\": args.local_log_path.replace('/var/snap/amazon-ssm-agent/6312/dev/','C:/Users/jeffe/'),\n",
    "    }\n",
    ")\n",
    "\n",
    "# run\n",
    "main.run_experiment(args)\n",
    "\n",
    "# run without this first\n",
    "dargs.update({'tune_n_trials': None})\n",
    "\n",
    "#################### only limit 7 days\n",
    "windows = [(0,7)]\n",
    "for window in windows:\n",
    "    dargs.update({\"min_days_on_crrt\": window[0],\n",
    "                \"max_days_on_crrt\": window[1]})\n",
    "    main.run_experiment(args)\n",
    "\n",
    "#################### multiple windows and slides\n",
    "# num_days_to_slide = 7\n",
    "# windows = [(0,7),(8,14), (15,200)]\n",
    "\n",
    "# for i in range(1,num_days_to_slide):\n",
    "#     dargs.update({\"slide_window_by\": -i})\n",
    "#     main.run_experiment(args)\n",
    "\n",
    "# for window in windows:\n",
    "#     dargs.update({\"min_days_on_crrt\": window[0],\n",
    "#                 \"max_days_on_crrt\": window[1]})\n",
    "\n",
    "#     for i in range(0,num_days_to_slide):\n",
    "#         dargs.update({\"slide_window_by\": -i})\n",
    "#         main.run_experiment(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Run with explanations\n",
    "\n",
    "dargs.update(\n",
    "    {\n",
    "        \"run_name\": 'post_eval',\n",
    "        \"ucla_crrt_data_dir\": \"C:/Users/jeffe/OneDrive - UCLA IT Services/UCLA/2023_Winter/Rotation/Data/UCLA\",\n",
    "        \"ucla_control_data_dir\": \"C:/Users/jeffe/OneDrive - UCLA IT Services/UCLA/2023_Winter/Rotation/Data/UCLA/Controls\",\n",
    "        \"cedars_crrt_data_dir\": \"C:/Users/jeffe/OneDrive - UCLA IT Services/UCLA/2023_Winter/Rotation/Data/Cedars\",\n",
    "        \"best_model_path\": args.best_model_path.replace('/var/snap/amazon-ssm-agent/6312/dev/','C:/Users/jeffe/'),\n",
    "        \"local_log_path\": args.local_log_path.replace('/var/snap/amazon-ssm-agent/6312/dev/','C:/Users/jeffe/'),\n",
    "    }\n",
    ")\n",
    "\n",
    "dargs.update(\n",
    "    {\n",
    "    'plot_names': [\"shap_explain\", \"randomness\", \"error_viz\"]\n",
    "    }\n",
    ")\n",
    "\n",
    "dargs.update({'tune_n_trials': None})\n",
    "\n",
    "# run\n",
    "main.run_experiment(args)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Curves for multiple evaluation cohorts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(curve_names, curve_fns, curve_params, runs, subgroups, subgroup_labels, plt_labels, colors):\n",
    "    for curve_name, curve, curve_param in zip(\n",
    "            curve_names,\n",
    "            curve_fns,\n",
    "            curve_params\n",
    "        ):\n",
    "            \n",
    "            metric_name = curve_param['metric']\n",
    "\n",
    "            x_axis_values = []\n",
    "            y_axis_values = []\n",
    "            legend = []\n",
    "\n",
    "            if \"calibration_curve\" in curve_name:\n",
    "                    legend.append('Perfect Classifier')\n",
    "\n",
    "            for i in range(len(subgroups)):\n",
    "\n",
    "                for j in range(len(runs)):\n",
    "                    run = client.get_run(runs[j])\n",
    "                    \n",
    "                    modeln = run.data.tags['modeln']\n",
    "                    prefix = f\"{modeln}_test{subgroups[i]}\"\n",
    "\n",
    "                    metrics = run.data.metrics\n",
    "\n",
    "                    experiment_id = client.get_experiment_by_name(\"static_learning\").experiment_id\n",
    "                    \n",
    "                    predict_probas = pickle.load(open(join(mlflow_path, experiment_id, run.info.run_id, \"artifacts\", \"predict_probas\", f\"{prefix}__predict_probas.pkl\"), 'rb'))\n",
    "                    labels = pickle.load(open(join(mlflow_path, experiment_id, run.info.run_id, \"artifacts\", \"predict_probas\", f\"{prefix}__labels.pkl\"), 'rb'))\n",
    "\n",
    "                    comparison = pd.merge(predict_probas.to_frame(),labels.to_frame(),how='inner', on=['IP_PATIENT_ID','Start Date', 'DATE'])\n",
    "                    y_true = comparison['recommend_crrt'].values\n",
    "                    y_pred = comparison[0].values\n",
    "\n",
    "                    figure = curve.from_predictions(y_true, y_pred)\n",
    "                    x_axis, y_axis = getattr(figure, curve_param[\"labels\"][0]), getattr(figure, curve_param[\"labels\"][1])\n",
    "                    x_axis_values.append(x_axis)\n",
    "                    y_axis_values.append(y_axis)\n",
    "                    plt.close()\n",
    "                    legend_txt = f\"{subgroup_labels[i]} {plt_labels[j]} ({metric_name.upper()}={metrics[prefix+'__'+metric_name]:.3f})\\n95% CI = {metrics[prefix+'__'+metric_name+'_CI_low']:.3f}-{metrics[prefix+'__'+metric_name+'_CI_high']:.3f}\"\n",
    "                    legend.append(legend_txt.strip())\n",
    "                \n",
    "                \n",
    "            figure = curve.from_predictions(y_true, y_pred, pos_label=1)\n",
    "            for artist in plt.gca().lines + plt.gca().collections:\n",
    "                artist.remove()\n",
    "            name = f\"test_{subgroup_labels[i]}_{curve_name}\"\n",
    "            # figure.figure_.suptitle(name)\n",
    "            print(name)\n",
    "\n",
    "            if \"calibration_curve\" in curve_name:\n",
    "                figure.ax_.plot([0, 1], [0, 1], \":k\")\n",
    "\n",
    "            for i in range(len(x_axis_values)):\n",
    "                figure.ax_.plot(x_axis_values[i], y_axis_values[i], color=colors[i])\n",
    "            \n",
    "            if len(x_axis_values)> 2:\n",
    "                figure.ax_.legend(legend,loc=\"upper left\", bbox_to_anchor=(0.55, 0.75),)\n",
    "            else:\n",
    "                if 'pr_curve' in curve_name:\n",
    "                    figure.ax_.legend(legend,loc=\"upper right\")\n",
    "                else:\n",
    "                    figure.ax_.legend(legend,loc=\"lower right\")\n",
    "            fig = plt.gcf()\n",
    "            fig.set_size_inches(3.75, 3.75)\n",
    "            plt.savefig(f'./posthoc/{name}.svg', format='svg',  bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.static_models import CURVE_MAP\n",
    "\n",
    "CURVE_PARAMS = {\n",
    "    \"calibration_curve\": {\n",
    "        \"labels\": (\"prob_pred\", \"prob_true\"),\n",
    "        \"limits\": None,\n",
    "        \"metric\": \"brier\",\n",
    "    },\n",
    "    \"roc_curve\": {\"labels\": (\"fpr\", \"tpr\"), \"limits\": (0, 1), \"metric\": \"auroc\"},\n",
    "    \"pr_curve\": {\"labels\": (\"recall\", \"precision\"), \"limits\": None, \"metric\": \"ap\"},\n",
    "    \"det_curve\": {\"labels\": (\"fpr\", \"fnr\"), \"limits\": None, \"metric\": \"accuracy\"},\n",
    "}\n",
    "\n",
    "import os\n",
    "os.makedirs('./posthoc', exist_ok=True)\n",
    "\n",
    "curve_names = args.curve_names\n",
    "curve_fns = [CURVE_MAP[metric] for metric in curve_names]\n",
    "curve_params = [CURVE_PARAMS[metric] for metric in curve_names]\n",
    "\n",
    "plt_labels = ['Test', \"External Test\"]\n",
    "runs = ['a07635aa0e50492d811d0ac7d9e807ac', '548afa05e3ee42208c20a2557dc1800a']\n",
    "runs = ['125c0fb5c21f4533a45a9258822de83e', 'ce12b0e992014d30a3d0ee1d44610dc5']\n",
    "\n",
    "subgroups = [\"\",]\n",
    "subgroup_labels = [\"\"]\n",
    "colors = ['tab:blue', 'tab:orange']\n",
    "plot_metrics(curve_names, curve_fns, curve_params, runs, subgroups, subgroup_labels, plt_labels, colors)\n",
    "\n",
    "subgroups = [\"_heart\", \"_liver\", \"_infection\"]\n",
    "subgroup_labels = [\"Heart\", \"Liver\", \"Infection\"]\n",
    "colors = ['tab:green', 'tab:red', 'tab:purple', 'tab:brown','tab:pink', 'tab:gray']\n",
    "plot_metrics(curve_names, curve_fns, curve_params, runs, subgroups, subgroup_labels, plt_labels, colors)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Barplots for multiple evaluation cohort together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs('./posthoc', exist_ok=True)\n",
    "metric_names = args.metric_names\n",
    "\n",
    "def subgroup_forest(metric_names, plt_labels, runs, subgroups, subgroup_labels, subgroup_categories, tag=''):\n",
    "\n",
    "    for metric_name in metric_names:\n",
    "\n",
    "        grouped_metric_vals = []\n",
    "        errors_low = []\n",
    "        errors_high = []\n",
    "            \n",
    "        for i in range(len(runs)):\n",
    "            run = client.get_run(runs[i])\n",
    "            \n",
    "            modeln = run.data.tags['modeln']\n",
    "\n",
    "            metrics = run.data.metrics\n",
    "\n",
    "            metric_values = []\n",
    "            metric_values_low = []\n",
    "            metric_values_high = []\n",
    "                \n",
    "            for j in range(len(subgroups)):\n",
    "                \n",
    "                prefix = f\"{modeln}_test{subgroups[j]}\"\n",
    "                \n",
    "                metric_values.append(metrics[prefix+'__'+metric_name])\n",
    "                metric_values_low.append(metrics[prefix+'__'+metric_name+'_CI_low'])\n",
    "                metric_values_high.append(metrics[prefix+'__'+metric_name+'_CI_high'])\n",
    "            \n",
    "            error_low = np.array(metric_values) - np.array(metric_values_low)\n",
    "            error_high = np.array(metric_values_high) - np.array(metric_values)\n",
    "            \n",
    "            grouped_metric_vals.append(metric_values)\n",
    "            errors_low.append(error_low)\n",
    "            errors_high.append(error_high)\n",
    "        \n",
    "        width = 0.25\n",
    "        multiplier = 0\n",
    "        \n",
    "        fig, ax = plt.subplots()\n",
    "\n",
    "        x = []\n",
    "        grouping_x = []\n",
    "        groupings = []\n",
    "        prev_grouping = None\n",
    "        current_grouping = None\n",
    "        index = len(subgroup_labels) + len(np.unique(subgroup_categories)) - 1\n",
    "        for i in range(len(subgroup_labels)):\n",
    "            current_grouping = subgroup_categories[i]\n",
    "            if current_grouping != prev_grouping:\n",
    "                grouping_x.append(index)\n",
    "                groupings.append(current_grouping)\n",
    "                index -= 1\n",
    "                prev_grouping = current_grouping\n",
    "\n",
    "            x.append(index)\n",
    "            index -= 1\n",
    "        x = np.array(x)\n",
    "        \n",
    "        for i in range(len(plt_labels)):\n",
    "            offset = width * multiplier\n",
    "\n",
    "            # ax.bar(x + offset, grouped_metric_vals[i], width, label=plt_labels[i], yerr=[errors_low[i], errors_high[i]])\n",
    "            # plt.errorbar(x + offset, grouped_metric_vals[i], yerr=[errors_low[i], errors_high[i]], marker=\"d\", capsize=5, elinewidth=2,label=plt_labels[i])\n",
    "            plt.errorbar(grouped_metric_vals[i], x + offset, xerr=[errors_low[i], errors_high[i]], marker=\"D\", capsize=3, elinewidth=1,label=plt_labels[i], linestyle='none')\n",
    "\n",
    "            multiplier += 1\n",
    "        \n",
    "        # ax.plot([0., x[-1]], [grouped_metric_vals[0][0], grouped_metric_vals[0][0]], \"k--\")\n",
    "        # ax.plot([0., x[-1]], [grouped_metric_vals[1][0], grouped_metric_vals[1][0]], \"k--\")\n",
    "        ax.plot([grouped_metric_vals[0][0], grouped_metric_vals[0][0]], [0., x[0]], \"k--\", linewidth=1)\n",
    "        try:\n",
    "            ax.plot([grouped_metric_vals[1][0], grouped_metric_vals[1][0]], [0., x[0]], \"k--\", linewidth=1)\n",
    "        except:\n",
    "            pass\n",
    "        ax.set_yticks(grouping_x, groupings, minor=False, fontweight='bold')\n",
    "        ax.set_yticks(x + width, subgroup_labels, minor=True)\n",
    "        ax.set_xlim([0,1])\n",
    "        ax.tick_params(axis='y', which='major', length=0)\n",
    "\n",
    "        # plt.yticks(ha='left')\n",
    "\n",
    "        # ax.set_title(name)\n",
    "        ax.set_xlabel(metric_name.upper())\n",
    "\n",
    "        name = f\"test_{metric_name}_subgroup_{tag}\" \n",
    "        print(name)\n",
    "        ax.legend()\n",
    "        fig = plt.gcf()\n",
    "        fig.set_size_inches(3, 10)\n",
    "        plt.savefig(f'./posthoc/{name}.svg', format='svg',  bbox_inches=\"tight\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UCLA -> UCLA + CEDARS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_labels = ['Test', \"External Test\"]\n",
    "runs = ['125c0fb5c21f4533a45a9258822de83e', 'ce12b0e992014d30a3d0ee1d44610dc5']\n",
    "subgroups = [\"\", \"_heart\", \"_liver\", \"_infection\",'_no_heart_liver_infection',\n",
    "            '_female','_male', \n",
    "            '_American Indian or Alaska Native','_Asian','_Black or African American','_Native Hawaiian or Other Pacific Islander','_Multiple Races','_Unknown','_White or Caucasian',\n",
    "            '_Hispanic or Latino','_Not Hispanic or Latino',\n",
    "            '_age_20_to_30', '_age_30_to_40', '_age_40_to_50', '_age_50_to_60', '_age_60_to_70', '_age_70_to_80','_age_80_to_90','_age_90_to_100']\n",
    "subgroup_labels = [\"all\", \"heart\", \"liver\", \"infection\",\"no heart,liver,\\ninfection\",\n",
    "                   'female','male', \n",
    "            'American Indian\\nor Alaska Native','Asian','Black or African American','Native Hawaiian or\\nOther Pacific Islander','Multiple Races','Unknown','White or Caucasian',\n",
    "            'Hispanic or Latino','Not Hispanic or Latino',\n",
    "            '20 to 30', '30 to 40', '40 to 50', '50 to 60', '60 to 70', '70 to 80','80 to 90','90 to 100']\n",
    "subgroup_categories = [\"indicator\", \"indicator\", \"indicator\", \"indicator\",\"indicator\",\n",
    "                   'sex','sex', \n",
    "            'race','race','race','race','race','race','race',\n",
    "            'ethnicity','ethnicity',\n",
    "            'age','age','age','age','age','age','age','age']\n",
    "subgroup_forest(metric_names, plt_labels, runs, subgroups, subgroup_labels, subgroup_categories)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cedars -> UCLA + CEDARS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_labels = ['Test', \"External Test\"]\n",
    "runs = ['a07635aa0e50492d811d0ac7d9e807ac', '548afa05e3ee42208c20a2557dc1800a']\n",
    "subgroups = [\"\", \"_heart\", \"_liver\", \"_infection\",'_no_heart_liver_infection',\n",
    "            '_female','_male', \n",
    "            '_Asian','_Black or African American','_Multiple Races','_Unknown','_White or Caucasian',\n",
    "            '_Hispanic or Latino','_Not Hispanic or Latino',\n",
    "            '_age_20_to_30', '_age_30_to_40', '_age_40_to_50', '_age_50_to_60', '_age_60_to_70', '_age_70_to_80','_age_80_to_90','_age_90_to_100']\n",
    "subgroup_labels = [\"all\", \"heart\", \"liver\", \"infection\",\"no heart,liver,\\ninfection\",\n",
    "                   'female','male', \n",
    "            'Asian','Black or African American','Multiple Races','Unknown','White or Caucasian',\n",
    "            'Hispanic or Latino','Not Hispanic or Latino',\n",
    "            '20 to 30', '30 to 40', '40 to 50', '50 to 60', '60 to 70', '70 to 80','80 to 90','90 to 100']\n",
    "subgroup_categories = [\"indicator\", \"indicator\", \"indicator\", \"indicator\",\"indicator\",\n",
    "                   'sex','sex', \n",
    "            'race','race','race','race','race',\n",
    "            'ethnicity','ethnicity',\n",
    "            'age','age','age','age','age','age','age','age']\n",
    "subgroup_forest(metric_names, plt_labels, runs, subgroups, subgroup_labels, subgroup_categories)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BOTH\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_labels = ['Test']\n",
    "runs = ['7bbdb269ea9041f799fa9de7e7d34b45']\n",
    "subgroups = [\"\", \"_heart\", \"_liver\", \"_infection\",'_no_heart_liver_infection',\n",
    "            '_female','_male', \n",
    "            '_Asian','_Black or African American','_Multiple Races','_Unknown','_White or Caucasian',\n",
    "            '_Hispanic or Latino','_Not Hispanic or Latino',\n",
    "            '_age_20_to_30', '_age_30_to_40', '_age_40_to_50', '_age_50_to_60', '_age_60_to_70', '_age_70_to_80','_age_80_to_90','_age_90_to_100']\n",
    "subgroup_labels = [\"all\", \"heart\", \"liver\", \"infection\",\"no heart,liver,\\ninfection\",\n",
    "                   'female','male', \n",
    "            'Asian','Black or African American','Multiple Races','Unknown','White or Caucasian',\n",
    "            'Hispanic or Latino','Not Hispanic or Latino',\n",
    "            '20 to 30', '30 to 40', '40 to 50', '50 to 60', '60 to 70', '70 to 80','80 to 90','90 to 100']\n",
    "subgroup_categories = [\"indicator\", \"indicator\", \"indicator\", \"indicator\",\"indicator\",\n",
    "                   'sex','sex', \n",
    "            'race','race','race','race','race',\n",
    "            'ethnicity','ethnicity',\n",
    "            'age','age','age','age','age','age','age','age']\n",
    "subgroup_forest(metric_names, plt_labels, runs, subgroups, subgroup_labels, subgroup_categories)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_labels = ['Test', \"External Test\"]\n",
    "runs = ['52d929585bd84345a5007ec99e1f3185', '5801be55809c4e3e91478d26ee0ee614']\n",
    "subgroups = [\"\", \"_heart\", \"_liver\", \"_infection\",'_no_heart_liver_infection',\n",
    "            '_female','_male', \n",
    "            '_Asian','_Black or African American','_Unknown','_White or Caucasian',\n",
    "            '_Hispanic or Latino','_Not Hispanic or Latino',\n",
    "            '_age_20_to_30', '_age_30_to_40', '_age_40_to_50', '_age_50_to_60', '_age_60_to_70', '_age_70_to_80','_age_80_to_90','_age_90_to_100']\n",
    "subgroup_labels = [\"all\", \"heart\", \"liver\", \"infection\",\"no heart,liver,\\ninfection\",\n",
    "                   'female','male', \n",
    "            'Asian','Black or African American','Unknown','White or Caucasian',\n",
    "            'Hispanic or Latino','Not Hispanic or Latino',\n",
    "            '20 to 30', '30 to 40', '40 to 50', '50 to 60', '60 to 70', '70 to 80','80 to 90','90 to 100']\n",
    "subgroup_categories = [\"indicator\", \"indicator\", \"indicator\", \"indicator\",\"indicator\",\n",
    "                   'sex','sex', \n",
    "            'race','race','race','race',\n",
    "            'ethnicity','ethnicity',\n",
    "            'age','age','age','age','age','age','age','age']\n",
    "subgroup_forest(metric_names, plt_labels, runs, subgroups, subgroup_labels, subgroup_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_labels = ['Test', \"External Test\"]\n",
    "runs = ['cf50989ed9e24cf3aefd4b6232c40ff5', 'b985f4b14d9e42da85dc296ce9e64118']\n",
    "subgroups = [\"\", \"_heart\", \"_liver\", \"_infection\",'_no_heart_liver_infection',\n",
    "            '_female','_male', \n",
    "            '_Asian','_Black or African American','_Multiple Races','_Unknown','_White or Caucasian',\n",
    "            '_Hispanic or Latino','_Not Hispanic or Latino',\n",
    "            '_age_20_to_30', '_age_30_to_40', '_age_40_to_50', '_age_50_to_60', '_age_60_to_70', '_age_70_to_80','_age_80_to_90','_age_90_to_100']\n",
    "subgroup_labels = [\"all\", \"heart\", \"liver\", \"infection\",\"no heart,liver,\\ninfection\",\n",
    "                   'female','male', \n",
    "            'Asian','Black or African American','Multiple Races','Unknown','White or Caucasian',\n",
    "            'Hispanic or Latino','Not Hispanic or Latino',\n",
    "            '20 to 30', '30 to 40', '40 to 50', '50 to 60', '60 to 70', '70 to 80','80 to 90','90 to 100']\n",
    "subgroup_categories = [\"indicator\", \"indicator\", \"indicator\", \"indicator\",\"indicator\",\n",
    "                   'sex','sex', \n",
    "            'race','race','race','race','race',\n",
    "            'ethnicity','ethnicity',\n",
    "            'age','age','age','age','age','age','age','age']\n",
    "subgroup_forest(metric_names, plt_labels, runs, subgroups, subgroup_labels, subgroup_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_labels = ['Test']\n",
    "runs = ['e7538934abdf4977af24b114fcac83d9']\n",
    "subgroups = [\"\", \"_heart\", \"_liver\", \"_infection\",'_no_heart_liver_infection',\n",
    "            '_female','_male', \n",
    "            '_Asian','_Black or African American','_Multiple Races','_Unknown','_White or Caucasian',\n",
    "            '_Hispanic or Latino','_Not Hispanic or Latino',\n",
    "            '_age_20_to_30', '_age_30_to_40', '_age_40_to_50', '_age_50_to_60', '_age_60_to_70', '_age_70_to_80','_age_80_to_90','_age_90_to_100']\n",
    "subgroup_labels = [\"all\", \"heart\", \"liver\", \"infection\",\"no heart,liver,\\ninfection\",\n",
    "                   'female','male', \n",
    "            'Asian','Black or African American','Multiple Races','Unknown','White or Caucasian',\n",
    "            'Hispanic or Latino','Not Hispanic or Latino',\n",
    "            '20 to 30', '30 to 40', '40 to 50', '50 to 60', '60 to 70', '70 to 80','80 to 90','90 to 100']\n",
    "subgroup_categories = [\"indicator\", \"indicator\", \"indicator\", \"indicator\",\"indicator\",\n",
    "                   'sex','sex', \n",
    "            'race','race','race','race','race',\n",
    "            'ethnicity','ethnicity',\n",
    "            'age','age','age','age','age','age','age','age']\n",
    "subgroup_forest(metric_names, plt_labels, runs, subgroups, subgroup_labels, subgroup_categories)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rolling window"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UCLA -> UCLA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_rolling_window(metric_names, subgroups, subgroup_labels, runs, plt_labels, groups, colors=None):\n",
    "    for metric_name in metric_names:\n",
    "            \n",
    "        for i in range(len(subgroups)):\n",
    "            \n",
    "            grouped_metric_vals = []\n",
    "            errors_low = []\n",
    "            errors_high = []\n",
    "\n",
    "            for j in range(len(runs)):\n",
    "                metric_values = []\n",
    "                metric_values_low = []\n",
    "                metric_values_high = []\n",
    "            \n",
    "                for k in range(len(runs[j])):\n",
    "\n",
    "                    run = client.get_run(runs[j][k])\n",
    "                \n",
    "                    modeln = run.data.tags['modeln']\n",
    "                    prefix = f\"{modeln}_test{subgroups[i]}\"\n",
    "\n",
    "                    metrics = run.data.metrics\n",
    "                    \n",
    "                    metric_values.append(metrics[prefix+'__'+metric_name])\n",
    "                    metric_values_low.append(metrics[prefix+'__'+metric_name+'_CI_low'])\n",
    "                    metric_values_high.append(metrics[prefix+'__'+metric_name+'_CI_high'])\n",
    "                \n",
    "                error_low = np.array(metric_values) - np.array(metric_values_low)\n",
    "                error_high = np.array(metric_values_high) - np.array(metric_values)\n",
    "                \n",
    "                grouped_metric_vals.append(metric_values)\n",
    "                errors_low.append(error_low)\n",
    "                errors_high.append(error_high)\n",
    "\n",
    "                name = f\"test_{metric_name}_{subgroup_labels[i]}_{groups[j]}\"\n",
    "                \n",
    "                fig, ax = plt.subplots()\n",
    "                x = np.arange(len(plt_labels))\n",
    "\n",
    "                plt.errorbar(x, metric_values, yerr=[error_low, error_high], marker=\"d\",linestyle='--',capsize=5, elinewidth=2,)\n",
    "                ax.set_xticks(x, plt_labels)\n",
    "                # ax.set_title(name)\n",
    "                ax.set_ylabel(metric_name.upper())\n",
    "                ax.set_xlabel('Days before start date')\n",
    "                print(name)\n",
    "                fig = plt.gcf()\n",
    "                fig.set_size_inches(5, 3)\n",
    "                plt.show()\n",
    "                \n",
    "            fig, ax = plt.subplots()\n",
    "            name = f\"test_{metric_name}_{subgroup_labels[i]}\"\n",
    "\n",
    "            width = 0.1\n",
    "            multiplier = 0\n",
    "            x = np.arange(len(plt_labels))\n",
    "\n",
    "            for j in range(len(groups)):\n",
    "                offset = width * multiplier\n",
    "\n",
    "                # ax.bar(x + offset, grouped_metric_vals[i], width, label=plt_labels[i], yerr=[errors_low[i], errors_high[i]])\n",
    "\n",
    "                if colors is not None:\n",
    "                    plt.errorbar(x + offset, grouped_metric_vals[j], yerr=[errors_low[j], errors_high[j]], marker=\"d\",linestyle='--', capsize=5, elinewidth=2,label=groups[j], color=colors[j])\n",
    "                else:\n",
    "                    plt.errorbar(x + offset, grouped_metric_vals[j], yerr=[errors_low[j], errors_high[j]], marker=\"d\",linestyle='--', capsize=5, elinewidth=2,label=groups[j])\n",
    "                \n",
    "                multiplier += 1\n",
    "            \n",
    "            ax.set_xticks(x + width, plt_labels)\n",
    "            # ax.set_title(name)\n",
    "            ax.set_ylabel(metric_name.upper())\n",
    "            ax.set_xlabel('Days before start date')\n",
    "            print(name)\n",
    "            ax.legend()\n",
    "            fig = plt.gcf()\n",
    "            fig.set_size_inches(5, 3)\n",
    "            plt.savefig(f'./posthoc/{name}.svg', format='svg',  bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_names = args.metric_names\n",
    "metric_names = ['auroc']\n",
    "\n",
    "\n",
    "groups = ['all', '0-7 days', '8-14 days', '15+']\n",
    "\n",
    "plt_labels = ['6', \"5\", '4', \"3\", '2', \"1\", '0']\n",
    "runs = [['c1e1215a95d140eda058a5bacc17a8e7',\n",
    "        '73ade10083c443b6978c3d2ce5d4a766',\n",
    "        '0d73855b2f8b40babc774cdc019ac3f5',\n",
    "        '5bbd13f3ad3343f9800042cc4d271d74',\n",
    "        'b2f35a3c973a4aee9b422edd31642c08',\n",
    "        'ee2eeff4537c49ffb6a455b14aeec715',\n",
    "        'f899fd8ea23f44c38e89c19a937b4111'],\n",
    "        ['5e67a99b15534b9e8f50da8b7e5eddbd',\n",
    "        'b48f1bf080c7429b9c819b7fc33b6a57',\n",
    "        '4c990d3587f64321bf3167b9e9baf6b3',\n",
    "        'c030454e79f04e618cb20debdbbc4fee',\n",
    "        'b6321863269f40a69a57bd54022dff75',\n",
    "        '4865ff3889bb471dabf5dcfbd1decd6a',\n",
    "        '52d929585bd84345a5007ec99e1f3185',],\n",
    "        ['0a1b37b147b54e719fb16bbca6ef56a2',\n",
    "        '0116d54187414a03bb9bd8d7839db17b',\n",
    "        '6c0953cf60d749b9aebcaf8d1e649478',\n",
    "        'd498676e8a094294b2106bf3bd80f45f',\n",
    "        '4b5e4715a56b4e8cbc65fb78b0d44241',\n",
    "        'd19c5708af16404697bc525979a2ad0d',\n",
    "        '56bc330c3743496d87f2450961dc91d8',],\n",
    "        ['29eeb2b6e46d49ceb08de0d294a8bfe8',\n",
    "        '288e7a8556934ee18f4ab7b42f33fbf6',\n",
    "        '8bb152da9dcd457d833cadf7e96673a4',\n",
    "        '80149a987aec45feac6c399e8603afea',\n",
    "        'd81bc25a35c84feaad87bf130635f4c3',\n",
    "        '577750b7357a45e2a51c01fced390d57',\n",
    "        '2d6b2665f78942278b7add6f17f40906',]]\n",
    "\n",
    "\n",
    "subgroups = [\"\", \"_heart\", \"_liver\", \"_infection\"]\n",
    "subgroup_labels = [\"all\", \"heart\", \"liver\", \"infection\"]\n",
    "plot_rolling_window(metric_names, subgroups, subgroup_labels, runs, plt_labels, groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_names = args.metric_names\n",
    "metric_names = ['auroc']\n",
    "\n",
    "\n",
    "groups = ['all', '0-7 days', '8-14 days', '15+']\n",
    "groups = ['all', '0-7 days']\n",
    "plt_labels = [ \"-5\", '-4', \"-3\", '-2', \"-1\", '0']\n",
    "runs = [[#'c1e1215a95d140eda058a5bacc17a8e7',\n",
    "        '73ade10083c443b6978c3d2ce5d4a766',\n",
    "        '0d73855b2f8b40babc774cdc019ac3f5',\n",
    "        '5bbd13f3ad3343f9800042cc4d271d74',\n",
    "        'b2f35a3c973a4aee9b422edd31642c08',\n",
    "        'ee2eeff4537c49ffb6a455b14aeec715',\n",
    "        'f899fd8ea23f44c38e89c19a937b4111'],\n",
    "        [#'5e67a99b15534b9e8f50da8b7e5eddbd',\n",
    "        'b48f1bf080c7429b9c819b7fc33b6a57',\n",
    "        '4c990d3587f64321bf3167b9e9baf6b3',\n",
    "        'c030454e79f04e618cb20debdbbc4fee',\n",
    "        'b6321863269f40a69a57bd54022dff75',\n",
    "        '4865ff3889bb471dabf5dcfbd1decd6a',\n",
    "        '52d929585bd84345a5007ec99e1f3185',],\n",
    "        # ['0a1b37b147b54e719fb16bbca6ef56a2',\n",
    "        # '0116d54187414a03bb9bd8d7839db17b',\n",
    "        # '6c0953cf60d749b9aebcaf8d1e649478',\n",
    "        # 'd498676e8a094294b2106bf3bd80f45f',\n",
    "        # '4b5e4715a56b4e8cbc65fb78b0d44241',\n",
    "        # 'd19c5708af16404697bc525979a2ad0d',\n",
    "        # '56bc330c3743496d87f2450961dc91d8',],\n",
    "        # ['29eeb2b6e46d49ceb08de0d294a8bfe8',\n",
    "        # '288e7a8556934ee18f4ab7b42f33fbf6',\n",
    "        # '8bb152da9dcd457d833cadf7e96673a4',\n",
    "        # '80149a987aec45feac6c399e8603afea',\n",
    "        # 'd81bc25a35c84feaad87bf130635f4c3',\n",
    "        # '577750b7357a45e2a51c01fced390d57',\n",
    "        # '2d6b2665f78942278b7add6f17f40906',]\n",
    "        ]\n",
    "\n",
    "\n",
    "subgroups = [\"\", \"_heart\", \"_liver\", \"_infection\"]\n",
    "subgroup_labels = [\"all\", \"heart\", \"liver\", \"infection\"]\n",
    "plot_rolling_window(metric_names, subgroups, subgroup_labels, runs, plt_labels, groups)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UCLA -> CEDARS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_names = args.metric_names\n",
    "metric_names = ['auroc']\n",
    "\n",
    "\n",
    "groups = ['all', '0-7 days', '8-14 days', '15+']\n",
    "groups = ['all', '0-7 days']\n",
    "\n",
    "plt_labels = [\"-5\", '-4', \"-3\", '-2', \"-1\", '0']\n",
    "runs = [[#'bdc911c822c4415bb54ce89a313d1a7e',\n",
    "        '449f163e30484aebb90007d924825f39',\n",
    "        '50a9e848d8fd4aa9a5570fd6907042b8',\n",
    "        'c050ec741e624dbdac6ca292f6e08f77',\n",
    "        '9515d0823f0b425f8e97881de5478f41',\n",
    "        '54086b89dda9449e8b7d425fa6d13c28',\n",
    "        '796fe8106bd24d69a7c282a068916742'],\n",
    "        [#'e753c68e4ee74712a2e5a15017785c99',\n",
    "        'df136a09085c47caa61cc5843cfedcab',\n",
    "        '035f987b9e114c92a5c8bc08a96cc6f2',\n",
    "        '4a2a83cddb3b4826946fdbde73fa4790',\n",
    "        '13b8a6ef83d946dd941db5835277f16e',\n",
    "        'e96fdb411f444c7fb1eaf536aa3ec9ff',\n",
    "        '5801be55809c4e3e91478d26ee0ee614',],\n",
    "        # [#'59257af9f74d4717a1594ba2da17f35c',\n",
    "        # '2efd1ec507f44e3d83cbcacef03e7147',\n",
    "        # '0fcc2380c56745e8a60ab9b649bac676',\n",
    "        # 'f49df2ce4f4d4081aa614dd63f037e82',\n",
    "        # '53ca636a65134752bf9d955db639b609',\n",
    "        # '6c8218631d1940a280d5df494406304a',\n",
    "        # '5e3bca6c35e342b0b1945f216a90af90',],\n",
    "        # [#'ca0a4bb8f7724d82a566e161e1542c5b',\n",
    "        # '2c1c3138cdc0494b8e49b95764e63575',\n",
    "        # '26e491b66f00425d85a75e88818265b5',\n",
    "        # '205399c3b4a64ebdba056e56cf292a05',\n",
    "        # 'd6c385dd87984da28842ff7acd5ffdc7',\n",
    "        # 'acd3199f5fdc44d384af80cc6f7df62c',\n",
    "        # '70c939cd7f6a4a96839fb18119bc3a2e',]\n",
    "        ]\n",
    "\n",
    "\n",
    "subgroups = [\"\", \"_heart\", \"_liver\", \"_infection\"]\n",
    "subgroup_labels = [\"all\", \"heart\", \"liver\", \"infection\"]\n",
    "plot_rolling_window(metric_names, subgroups, subgroup_labels, runs, plt_labels, groups)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UCLA -> UCLA, UCLA -> CEDARS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_names = args.metric_names\n",
    "metric_names = ['auroc']\n",
    "\n",
    "\n",
    "groups = ['Test all', 'Test 0-7 days', 'External test all', 'External test 0-7 days']\n",
    "\n",
    "\n",
    "metric_names = args.metric_names\n",
    "metric_names = ['auroc']\n",
    "\n",
    "\n",
    "plt_labels = [ \"5\", '4', \"3\", '2', \"1\", '0']\n",
    "runs = [[#'c1e1215a95d140eda058a5bacc17a8e7',\n",
    "        '73ade10083c443b6978c3d2ce5d4a766',\n",
    "        '0d73855b2f8b40babc774cdc019ac3f5',\n",
    "        '5bbd13f3ad3343f9800042cc4d271d74',\n",
    "        'b2f35a3c973a4aee9b422edd31642c08',\n",
    "        'ee2eeff4537c49ffb6a455b14aeec715',\n",
    "        'f899fd8ea23f44c38e89c19a937b4111'],\n",
    "        [#'5e67a99b15534b9e8f50da8b7e5eddbd',\n",
    "        'b48f1bf080c7429b9c819b7fc33b6a57',\n",
    "        '4c990d3587f64321bf3167b9e9baf6b3',\n",
    "        'c030454e79f04e618cb20debdbbc4fee',\n",
    "        'b6321863269f40a69a57bd54022dff75',\n",
    "        '4865ff3889bb471dabf5dcfbd1decd6a',\n",
    "        '52d929585bd84345a5007ec99e1f3185',],\n",
    "        [#'bdc911c822c4415bb54ce89a313d1a7e',\n",
    "        '449f163e30484aebb90007d924825f39',\n",
    "        '50a9e848d8fd4aa9a5570fd6907042b8',\n",
    "        'c050ec741e624dbdac6ca292f6e08f77',\n",
    "        '9515d0823f0b425f8e97881de5478f41',\n",
    "        '54086b89dda9449e8b7d425fa6d13c28',\n",
    "        '796fe8106bd24d69a7c282a068916742'],\n",
    "        [#'e753c68e4ee74712a2e5a15017785c99',\n",
    "        'df136a09085c47caa61cc5843cfedcab',\n",
    "        '035f987b9e114c92a5c8bc08a96cc6f2',\n",
    "        '4a2a83cddb3b4826946fdbde73fa4790',\n",
    "        '13b8a6ef83d946dd941db5835277f16e',\n",
    "        'e96fdb411f444c7fb1eaf536aa3ec9ff',\n",
    "        '5801be55809c4e3e91478d26ee0ee614',],\n",
    "        # [#'59257af9f74d4717a1594ba2da17f35c',\n",
    "        # '2efd1ec507f44e3d83cbcacef03e7147',\n",
    "        # '0fcc2380c56745e8a60ab9b649bac676',\n",
    "        # 'f49df2ce4f4d4081aa614dd63f037e82',\n",
    "        # '53ca636a65134752bf9d955db639b609',\n",
    "        # '6c8218631d1940a280d5df494406304a',\n",
    "        # '5e3bca6c35e342b0b1945f216a90af90',],\n",
    "        # [#'ca0a4bb8f7724d82a566e161e1542c5b',\n",
    "        # '2c1c3138cdc0494b8e49b95764e63575',\n",
    "        # '26e491b66f00425d85a75e88818265b5',\n",
    "        # '205399c3b4a64ebdba056e56cf292a05',\n",
    "        # 'd6c385dd87984da28842ff7acd5ffdc7',\n",
    "        # 'acd3199f5fdc44d384af80cc6f7df62c',\n",
    "        # '70c939cd7f6a4a96839fb18119bc3a2e',]\n",
    "        ]\n",
    "\n",
    "\n",
    "subgroups = [\"\", \"_heart\", \"_liver\", \"_infection\"]\n",
    "subgroup_labels = [\"all\", \"heart\", \"liver\", \"infection\"]\n",
    "plot_rolling_window(metric_names, subgroups, subgroup_labels, runs, plt_labels, groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_names = args.metric_names\n",
    "metric_names = ['auroc']\n",
    "\n",
    "\n",
    "groups = ['Test all', 'Test 0-7 days', 'External test all', 'External test 0-7 days']\n",
    "colors = ['tab:blue', 'tab:green', 'tab:orange', 'tab:red']\n",
    "\n",
    "metric_names = args.metric_names\n",
    "metric_names = ['auroc']\n",
    "\n",
    "\n",
    "plt_labels = [ \"3\", '2', \"1\", '0']\n",
    "runs = [[#'c1e1215a95d140eda058a5bacc17a8e7',\n",
    "        #'73ade10083c443b6978c3d2ce5d4a766',\n",
    "        #'0d73855b2f8b40babc774cdc019ac3f5',\n",
    "        '5bbd13f3ad3343f9800042cc4d271d74',\n",
    "        'b2f35a3c973a4aee9b422edd31642c08',\n",
    "        'ee2eeff4537c49ffb6a455b14aeec715',\n",
    "        'f899fd8ea23f44c38e89c19a937b4111'],\n",
    "        [#'5e67a99b15534b9e8f50da8b7e5eddbd',\n",
    "        # 'b48f1bf080c7429b9c819b7fc33b6a57',\n",
    "        # '4c990d3587f64321bf3167b9e9baf6b3',\n",
    "        'c030454e79f04e618cb20debdbbc4fee',\n",
    "        'b6321863269f40a69a57bd54022dff75',\n",
    "        '4865ff3889bb471dabf5dcfbd1decd6a',\n",
    "        '52d929585bd84345a5007ec99e1f3185',],\n",
    "        [#'bdc911c822c4415bb54ce89a313d1a7e',\n",
    "        # '449f163e30484aebb90007d924825f39',\n",
    "        # '50a9e848d8fd4aa9a5570fd6907042b8',\n",
    "        'c050ec741e624dbdac6ca292f6e08f77',\n",
    "        '9515d0823f0b425f8e97881de5478f41',\n",
    "        '54086b89dda9449e8b7d425fa6d13c28',\n",
    "        '796fe8106bd24d69a7c282a068916742'],\n",
    "        [#'e753c68e4ee74712a2e5a15017785c99',\n",
    "        # 'df136a09085c47caa61cc5843cfedcab',\n",
    "        # '035f987b9e114c92a5c8bc08a96cc6f2',\n",
    "        '4a2a83cddb3b4826946fdbde73fa4790',\n",
    "        '13b8a6ef83d946dd941db5835277f16e',\n",
    "        'e96fdb411f444c7fb1eaf536aa3ec9ff',\n",
    "        '5801be55809c4e3e91478d26ee0ee614',],\n",
    "        # [#'59257af9f74d4717a1594ba2da17f35c',\n",
    "        # '2efd1ec507f44e3d83cbcacef03e7147',\n",
    "        # '0fcc2380c56745e8a60ab9b649bac676',\n",
    "        # 'f49df2ce4f4d4081aa614dd63f037e82',\n",
    "        # '53ca636a65134752bf9d955db639b609',\n",
    "        # '6c8218631d1940a280d5df494406304a',\n",
    "        # '5e3bca6c35e342b0b1945f216a90af90',],\n",
    "        # [#'ca0a4bb8f7724d82a566e161e1542c5b',\n",
    "        # '2c1c3138cdc0494b8e49b95764e63575',\n",
    "        # '26e491b66f00425d85a75e88818265b5',\n",
    "        # '205399c3b4a64ebdba056e56cf292a05',\n",
    "        # 'd6c385dd87984da28842ff7acd5ffdc7',\n",
    "        # 'acd3199f5fdc44d384af80cc6f7df62c',\n",
    "        # '70c939cd7f6a4a96839fb18119bc3a2e',]\n",
    "        ]\n",
    "\n",
    "\n",
    "subgroups = [\"\", \"_heart\", \"_liver\", \"_infection\"]\n",
    "subgroup_labels = [\"all\", \"heart\", \"liver\", \"infection\"]\n",
    "plot_rolling_window(metric_names, subgroups, subgroup_labels, runs, plt_labels, groups, colors=colors)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clinical impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.static_models import METRIC_MAP\n",
    "from sklearn.metrics import auc, det_curve, confusion_matrix\n",
    "\n",
    "\n",
    "conf_matrix = [\"TP\", \"FN\", \"TN\",\"FP\" ]\n",
    "metric_fns = [METRIC_MAP[metric] for metric in conf_matrix]\n",
    "\n",
    "plt_labels = ['UCLA', \"CEDARS\"]\n",
    "runs = ['a07635aa0e50492d811d0ac7d9e807ac', '548afa05e3ee42208c20a2557dc1800a']\n",
    "runs = ['125c0fb5c21f4533a45a9258822de83e', 'ce12b0e992014d30a3d0ee1d44610dc5']\n",
    "subgroups = [\"\", \"_heart\", \"_liver\", \"_infection\"]\n",
    "subgroup_labels = [\"all\", \"heart\", \"liver\", \"infection\"]\n",
    "\n",
    "colors = ['steelblue','lightcoral','lightblue','indianred']\n",
    "conf_matrix_label = ['Recommend CRRT, will benefit from CRRT','Do not recommend CRRT, will benefit from CRRT','Do not recommend CRRT, will not benefit from CRRT','Recommend CRRT, will not benefit from CRRT']\n",
    "conf_matrix_baseline_label = ['Put on CRRT, observe good outcome','','','Put on CRRT, obverve poor outcome']\n",
    "\n",
    "for i in range(len(subgroups)):\n",
    "\n",
    "    for j in range(len(runs)):\n",
    "        run = client.get_run(runs[j])\n",
    "        \n",
    "        modeln = run.data.tags['modeln']\n",
    "        prefix = f\"{modeln}_test{subgroups[i]}\"\n",
    "\n",
    "        metrics = run.data.metrics\n",
    "        \n",
    "        experiment_id = client.get_experiment_by_name(\"static_learning\").experiment_id\n",
    "        \n",
    "        predict_probas = pickle.load(open(join(mlflow_path, experiment_id, run.info.run_id, \"artifacts\", \"predict_probas\", f\"{prefix}__predict_probas.pkl\"), 'rb'))\n",
    "        labels = pickle.load(open(join(mlflow_path, experiment_id, run.info.run_id, \"artifacts\", \"predict_probas\", f\"{prefix}__labels.pkl\"), 'rb'))\n",
    "\n",
    "        comparison = pd.merge(predict_probas.to_frame(),labels.to_frame(),how='inner', on=['IP_PATIENT_ID','Start Date', 'DATE'])\n",
    "        y_true = comparison['recommend_crrt'].values\n",
    "        y_pred = comparison[0].values\n",
    "\n",
    "        grouping_labels = ['Current\\nStandard', 'Clinical ML\\nFN=0','Clinical ML\\nFN=2','Clinical ML\\nThresh=0.5']\n",
    "        \n",
    "        # Current clinical practice\n",
    "        conf_matrix_values = {metric: [] for metric in conf_matrix}\n",
    "        for metric_name, metric_fn in zip(conf_matrix,metric_fns):\n",
    "            conf_matrix_values[metric_name].append(metric_fn(y_true, y_true, 0.5))\n",
    "        conf_matrix_values['FP'] = conf_matrix_values['TN']\n",
    "        conf_matrix_values['TN'] = [0]\n",
    "\n",
    "        # Search for good threshold\n",
    "        fpr, fnr, thresholds = det_curve(y_true, y_pred)\n",
    "        use_thresh = []\n",
    "        for threshold in thresholds:\n",
    "            if confusion_matrix(y_true, (y_pred >= threshold).astype(int))[1, 0] == 0 \\\n",
    "                or confusion_matrix(y_true, (y_pred >= threshold).astype(int))[1, 0] == 2:\n",
    "                use_thresh.append(threshold)\n",
    "            if len(use_thresh) == len(grouping_labels)-2:\n",
    "                break\n",
    "        \n",
    "        for k in range(1,len(grouping_labels)-1):\n",
    "            for metric_name, metric_fn in zip(conf_matrix,metric_fns):\n",
    "                conf_matrix_values[metric_name].append(metric_fn(y_true, y_pred, use_thresh[k-1]))\n",
    "\n",
    "        # Current clinical practice\n",
    "        for metric_name, metric_fn in zip(conf_matrix,metric_fns):\n",
    "            conf_matrix_values[metric_name].append(metric_fn(y_true, y_pred, 0.5))\n",
    "            \n",
    "        fig, ax = plt.subplots()\n",
    "        bottom = np.zeros(len(grouping_labels)-1)\n",
    "        bottom_baseline = 0\n",
    "\n",
    "        for k, metric_name in enumerate(conf_matrix):\n",
    "            data = conf_matrix_values[metric_name]\n",
    "            if data[0] > 0:\n",
    "                p = ax.bar(grouping_labels[0], data[0], 0.5, label=conf_matrix_baseline_label[k], bottom=bottom_baseline, edgecolor='black',linestyle='--',color=colors[k], alpha=0.5)\n",
    "                bottom_baseline += data[0]\n",
    "                labels = [int(v) if v > 2 else \"\" for v in p.datavalues]    \n",
    "                ax.bar_label(p, labels=labels, label_type=\"center\")\n",
    "\n",
    "\n",
    "        for k, metric_name in enumerate(conf_matrix):\n",
    "            p = ax.bar(grouping_labels[1:], conf_matrix_values[metric_name][1:], 0.5, label=conf_matrix_label[k], bottom=bottom, color=colors[k])\n",
    "            bottom += conf_matrix_values[metric_name][1:]\n",
    "\n",
    "            labels = [int(v) if v > 2 else \"\" for v in p.datavalues]    \n",
    "            ax.bar_label(p, labels=labels, label_type=\"center\")\n",
    "\n",
    "        ax2 = ax.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "        ax2.set_ylabel('Cost savings per day ($)', color='m')  # we already handled the x-label with ax1\n",
    "        savings = np.array(conf_matrix_values['TN'][1:])+np.array(conf_matrix_values['FN'][1:])\n",
    "        \n",
    "        prices = [543, 3486/7, 2117/7, 276.70*1.06, 2607/7,3089/7,436*1.06, 3629.80, 1100, 3700]\n",
    "        ax2.errorbar(grouping_labels, [None]+list(savings*np.mean(prices)), color='m')\n",
    "        # ax2.errorbar(grouping_labels, [None]+list(savings*np.max(prices)), color='tab:green', linestyle='--')\n",
    "        # ax2.errorbar(grouping_labels, [None]+list(savings*np.min(prices)), color='tab:green', linestyle='--')\n",
    "        ax2.set_ylim([0, np.max(savings*np.mean(prices))+0.1*np.max(savings*np.mean(prices))])\n",
    "        ax2.tick_params(axis='y', labelcolor='m')\n",
    "\n",
    "        # ax.set_title(f\"Clinical impact_{subgroup_labels[i]}_{plt_labels[j]}\")\n",
    "        print(f\"Clinical impact_{subgroup_labels[i]}_{plt_labels[j]}\")\n",
    "        ax.legend(loc='upper left', bbox_to_anchor=(-0.1, -0.15),\n",
    "          fancybox=False, shadow=False, ncol=1)\n",
    "\n",
    "        ax.set_ylabel(\"Patient counts\")\n",
    "        fig = plt.gcf()\n",
    "        fig.set_size_inches(3.5, 3.5)\n",
    "        plt.savefig(f'./posthoc/Clinical impact_{subgroup_labels[i]}_{plt_labels[j]}.svg', format='svg',  bbox_inches=\"tight\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Randomness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "os.makedirs('./posthoc', exist_ok=True)\n",
    "\n",
    "df = pd.read_csv(\"C:/Users/jeffe/mlflow/mlruns/276694068661550192/1ac57520f1ad4393b5db65cd26bf56df/artifacts/xgb_test__dist_comparison_table.csv\")\n",
    "\n",
    "df_fntp = df[df['Unnamed: 0']=='fn_vs_tp']\n",
    "df_fntp_true = df_fntp[df_fntp['Reject H0']==True]\n",
    "df_fntp_true_var = df_fntp_true['Unnamed: 1']\n",
    "print(df_fntp_true['Reject H0'].value_counts())\n",
    "\n",
    "df_fntn = df[df['Unnamed: 0']=='fn_vs_tn']\n",
    "df_fntn_shared = df_fntn[df_fntn['Unnamed: 1'].isin(df_fntp_true_var)]\n",
    "print(df_fntn_shared['Reject H0'].value_counts())\n",
    "df_fntn_shared_false = df_fntn_shared[df_fntn_shared['Reject H0']==False]['Unnamed: 1']\n",
    "df_fntn_shared_true = df_fntn_shared[df_fntn_shared['Reject H0']==True]['Unnamed: 1']\n",
    "\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.hist(df_fntp_true[df_fntp_true['Unnamed: 1'].isin(df_fntn_shared_false)]['Effect Size'], bins=40, range=(0,2), \n",
    "        label=f\"FN features found in TN (N={len(df_fntp_true[df_fntp_true['Unnamed: 1'].isin(df_fntn_shared_false)]['Effect Size'])})\")\n",
    "plt.hist(df_fntp_true[df_fntp_true['Unnamed: 1'].isin(df_fntn_shared_true)]['Effect Size'], bins=40, range=(0,2),\n",
    "         label=f\"FN features not found in TN (N={len(df_fntp_true[df_fntp_true['Unnamed: 1'].isin(df_fntn_shared_true)]['Effect Size'])})\")\n",
    "plt.xlabel('Effect size')\n",
    "plt.ylabel('Number of features')\n",
    "plt.ylim([0,60])\n",
    "plt.legend()\n",
    "plt.savefig('./posthoc/randomness_fn.svg', format='svg',  bbox_inches=\"tight\")\n",
    "\n",
    "plt.figure(figsize=(4,4))\n",
    "relevant = df_fntp_true[df_fntp_true['Unnamed: 1'].isin(df_fntn_shared_false)].sort_values('Effect Size')\n",
    "p = plt.barh(relevant['Unnamed: 1'][-10:], relevant['Effect Size'][-10:], alpha=0.4)\n",
    "plt.yticks(ha='left')\n",
    "plt.tick_params(axis=\"y\",direction=\"in\", pad=-10)\n",
    "plt.xlabel('Effect size')\n",
    "plt.xlim([0,2.05])\n",
    "plt.savefig('./posthoc/randomness_fn_feat.svg', format='svg',  bbox_inches=\"tight\")\n",
    "\n",
    "\n",
    "df_fptn = df[df['Unnamed: 0']=='fp_vs_tn']\n",
    "df_fptn_true = df_fptn[df_fptn['Reject H0']==True]\n",
    "df_fptn_true_var = df_fptn_true['Unnamed: 1']\n",
    "print(df_fptn_true['Reject H0'].value_counts())\n",
    "\n",
    "df_fptp = df[df['Unnamed: 0']=='fp_vs_tp']\n",
    "df_fptp_shared = df_fptp[df_fptp['Unnamed: 1'].isin(df_fptn_true_var)]\n",
    "print(df_fptp_shared['Reject H0'].value_counts())\n",
    "df_fptp_shared_false = df_fptp_shared[df_fptp_shared['Reject H0']==False]['Unnamed: 1']\n",
    "df_fptp_shared_true = df_fptp_shared[df_fptp_shared['Reject H0']==True]['Unnamed: 1']\n",
    "\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.hist(df_fptn_true[df_fptn_true['Unnamed: 1'].isin(df_fptp_shared_false)]['Effect Size'], bins=40, range=(0,2),\n",
    "         label=f\"FP features found in TP (N={len(df_fptn_true[df_fptn_true['Unnamed: 1'].isin(df_fptp_shared_false)]['Effect Size'])})\")\n",
    "plt.hist(df_fptn_true[df_fptn_true['Unnamed: 1'].isin(df_fptp_shared_true)]['Effect Size'], bins=40, range=(0,2),\n",
    "         label=f\"FP features not found in TP (N={len(df_fptn_true[df_fptn_true['Unnamed: 1'].isin(df_fptp_shared_true)]['Effect Size'])})\")\n",
    "plt.xlabel('Effect size')\n",
    "plt.ylabel('Number of features')\n",
    "plt.ylim([0,60])\n",
    "plt.legend()\n",
    "plt.savefig('./posthoc/randomness_fp.svg', format='svg',  bbox_inches=\"tight\")\n",
    "\n",
    "plt.figure(figsize=(4,4))\n",
    "relevant = df_fptn_true[df_fptn_true['Unnamed: 1'].isin(df_fptp_shared_false)].sort_values('Effect Size')\n",
    "plt.barh(relevant['Unnamed: 1'][-10:], relevant['Effect Size'][-10:], alpha=0.4)\n",
    "plt.yticks(ha='left')\n",
    "plt.tick_params(axis=\"y\",direction=\"in\", pad=-10)\n",
    "plt.xlabel('Effect size')\n",
    "plt.xlim([0,2.05])\n",
    "plt.savefig('./posthoc/randomness_fp_feat.svg', format='svg',  bbox_inches=\"tight\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crrtenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "88ac95e3320af9a902ad5fb0274d19f204ffbd00dc695a7b7dcd9954ec72a217"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
