{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.idle": "2021-02-26T00:55:03.680232Z",
     "shell.execute_reply": "2021-02-26T00:55:03.679685Z",
     "shell.execute_reply.started": "2021-02-26T00:55:03.443273Z"
    }
   },
   "outputs": [],
   "source": [
    "# I currently have 16 files (not including Bui_CRRT_files_email for syntax)\n",
    "\n",
    "# 16 files in total\n",
    "# 3 for static features\n",
    "# 9 for encounters (minus labs (1) and procedures (1)) - longitudinal features\n",
    "# 1 for mapping file\n",
    "# 1 for outcome file\n",
    "\n",
    "#data_dir = \"/home/davina/Private/dialysis-data\"\n",
    "data_dir = r\"C:\\Users\\arvin\\Documents\\ucla research\\CRRT project\"\n",
    "static_features = [\n",
    "    \"Allergies_19-000093_10082020.txt\",\n",
    "    \"Patient_Demographics_19-000093_10082020.txt\",\n",
    "    \"Social_History_19-000093_10082020.txt\",\n",
    "]\n",
    "encounters = [\n",
    "    \"enc_19-000093_10082020.txt\", # general visits to the doctors and general reasons\n",
    "    \"Encounter_Diagnoses_19-000093_10082020.txt\",\n",
    "    \"Encounters_19-000093_10082020.txt\",\n",
    "    \"Family_History_19-000093_10082020.txt\",\n",
    "    \"Flowsheet_Vitals_19-000093_10082020.txt\",\n",
    "    \"Hospital_Unit_Transfers_19-000093_10082020.txt\",\n",
    "#     \"Labs_19-000093_10082020.txt\",\n",
    "    \"Medications_19-000093_10082020.txt\",\n",
    "    \"problem_list_diagnoses_19-000093_10082020.txt\",\n",
    "    \"Problem_Lists_19-000093_10082020.txt\",\n",
    "#     \"Procedures_19-000093_10082020.txt\",\n",
    "]\n",
    "provider_mapping_file = \"providers_19-000093_10082020.txt\"\n",
    "outcome_file = \"CRRT Deidentified 2017-2019.csv\"\n",
    "# files = static_features + encounters\n",
    "files = static_features\n",
    "\n",
    "dfs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-26T00:55:03.681170Z",
     "iopub.status.busy": "2021-02-26T00:55:03.681015Z",
     "iopub.status.idle": "2021-02-26T00:55:03.692848Z",
     "shell.execute_reply": "2021-02-26T00:55:03.692328Z",
     "shell.execute_reply.started": "2021-02-26T00:55:03.681154Z"
    }
   },
   "outputs": [],
   "source": [
    "for file in files:\n",
    "    try:\n",
    "        dfs.append(pd.read_csv(f\"{data_dir}\\\\{file}\"))\n",
    "    except:\n",
    "        print(f\"Unexpected encoding in {file}\")\n",
    "        default_guess = \"cp1252\"\n",
    "        import os\n",
    "        # get file encoding using file -i and extracting name with sed\n",
    "        # ref: https://unix.stackexchange.com/a/393949\n",
    "        # -n: don't print unless we say. s/ search, .* match any, charset=, // remove text up until after =, print remaining\n",
    "        command = f\"file -i {data_dir}/{file} | sed -n 's/.*charset=//p'\"\n",
    "        # [:-1] ignore newline\n",
    "        encoding = os.popen(command).read()[:-1]\n",
    "        print(f\"Encoding was {encoding} instead of assumed utf-8.\")\n",
    "        if encoding == \"unknown-8bit\":\n",
    "            print(f\"Assuming {default_guess}...\")\n",
    "            dfs.append(pd.read_csv(f\"{data_dir}/{file}\",  encoding=default_guess))\n",
    "        else:\n",
    "            dfs.append(pd.read_csv(f\"{data_dir}/{file}\",  encoding=encoding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-26T00:55:03.695757Z",
     "iopub.status.busy": "2021-02-26T00:55:03.695611Z",
     "iopub.status.idle": "2021-02-26T00:55:03.703937Z",
     "shell.execute_reply": "2021-02-26T00:55:03.703467Z",
     "shell.execute_reply.started": "2021-02-26T00:55:03.695743Z"
    }
   },
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "combined = reduce(lambda df1, df2: pd.merge(df1, df2, on=\"IP_PATIENT_ID\", how=\"inner\"), dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-26T00:55:03.704638Z",
     "iopub.status.busy": "2021-02-26T00:55:03.704499Z",
     "iopub.status.idle": "2021-02-26T00:55:03.710555Z",
     "shell.execute_reply": "2021-02-26T00:55:03.710134Z",
     "shell.execute_reply.started": "2021-02-26T00:55:03.704624Z"
    }
   },
   "outputs": [],
   "source": [
    "# map provider id to type\n",
    "provider_mapping = pd.read_csv(f\"{data_dir}\\\\{provider_mapping_file}\")\n",
    "provider_mapping = dict(zip(provider_mapping[\"IP_PROVIDER_ID\"], provider_mapping[\"PROVIDER_TYPE\"]))\n",
    "combined[\"PCP_IP_PROVIDER_ID\"] = combined[\"PCP_IP_PROVIDER_ID\"].map(provider_mapping)\n",
    "combined.rename(columns={\"PCP_IP_PROVIDER_ID\" : \"PCP_PROVIDER_TYPE\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-26T00:55:03.711271Z",
     "iopub.status.busy": "2021-02-26T00:55:03.711134Z",
     "iopub.status.idle": "2021-02-26T00:55:03.746401Z",
     "shell.execute_reply": "2021-02-26T00:55:03.745960Z",
     "shell.execute_reply.started": "2021-02-26T00:55:03.711257Z"
    }
   },
   "outputs": [],
   "source": [
    "combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-26T00:55:03.747112Z",
     "iopub.status.busy": "2021-02-26T00:55:03.746959Z",
     "iopub.status.idle": "2021-02-26T00:55:03.750819Z",
     "shell.execute_reply": "2021-02-26T00:55:03.750389Z",
     "shell.execute_reply.started": "2021-02-26T00:55:03.747097Z"
    }
   },
   "outputs": [],
   "source": [
    "combined[\"IP_PATIENT_ID\"].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load + Preproc Outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-26T00:55:03.751523Z",
     "iopub.status.busy": "2021-02-26T00:55:03.751344Z",
     "iopub.status.idle": "2021-02-26T00:55:03.769652Z",
     "shell.execute_reply": "2021-02-26T00:55:03.769206Z",
     "shell.execute_reply.started": "2021-02-26T00:55:03.751507Z"
    }
   },
   "outputs": [],
   "source": [
    "# get first sheet only\n",
    "outcomes = pd.read_csv(f\"{data_dir}\\\\{outcome_file}\")\n",
    "\n",
    "# Exclude pediatric data\n",
    "#exclude_peds = outcomes[\"Hospital name\"] != \"UCLA MEDICAL CENTER- PEDIATRICS\"\n",
    "#outcomes = outcomes[exclude_peds]\n",
    "\n",
    "outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate Outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-26T00:55:12.288110Z",
     "iopub.status.busy": "2021-02-26T00:55:12.287524Z",
     "iopub.status.idle": "2021-02-26T00:55:12.303998Z",
     "shell.execute_reply": "2021-02-26T00:55:12.303210Z",
     "shell.execute_reply.started": "2021-02-26T00:55:12.288058Z"
    }
   },
   "outputs": [],
   "source": [
    "positive_outcomes = [\"Recov. renal funct.\", \"Transitioned to HD\"]\n",
    "negative_outcomes = [\"Palliative Care\", \"Expired \"] \n",
    "outcome_cols = positive_outcomes + negative_outcomes\n",
    "outcomes[outcome_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-26T00:55:12.999013Z",
     "iopub.status.busy": "2021-02-26T00:55:12.998506Z",
     "iopub.status.idle": "2021-02-26T00:55:13.020869Z",
     "shell.execute_reply": "2021-02-26T00:55:13.020184Z",
     "shell.execute_reply.started": "2021-02-26T00:55:12.998964Z"
    }
   },
   "outputs": [],
   "source": [
    "# Each row should have exactly 1 1.0 value (one-hot of the 4 cols)\n",
    "bad_rows = outcomes[outcome_cols].fillna(0).sum(axis=1) == 0\n",
    "outcomes[bad_rows]\n",
    "## TODO: Should i drop the bad row?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct outcome feature (recommend dialysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-26T00:55:14.009504Z",
     "iopub.status.busy": "2021-02-26T00:55:14.008981Z",
     "iopub.status.idle": "2021-02-26T00:55:14.022150Z",
     "shell.execute_reply": "2021-02-26T00:55:14.020662Z",
     "shell.execute_reply.started": "2021-02-26T00:55:14.009455Z"
    }
   },
   "outputs": [],
   "source": [
    "recommend_dialysis = (outcomes[\"Recov. renal funct.\"] == 1) | (outcomes[\"Transitioned to HD\"] == 1)\n",
    "outcomes[\"recommend_dialysis\"] =  recommend_dialysis.astype(int)\n",
    "\n",
    "# To combine with features\n",
    "outcome_df = outcomes[[\"IP_PATIENT_ID\", \"recommend_dialysis\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-26T00:55:53.783151Z",
     "iopub.status.busy": "2021-02-26T00:55:53.782800Z",
     "iopub.status.idle": "2021-02-26T00:55:53.789186Z",
     "shell.execute_reply": "2021-02-26T00:55:53.788222Z",
     "shell.execute_reply.started": "2021-02-26T00:55:53.783122Z"
    }
   },
   "outputs": [],
   "source": [
    "sum(outcome_df[\"recommend_dialysis\"])/len(outcome_df) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge features with outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-26T00:55:15.103707Z",
     "iopub.status.busy": "2021-02-26T00:55:15.103071Z",
     "iopub.status.idle": "2021-02-26T00:55:15.147605Z",
     "shell.execute_reply": "2021-02-26T00:55:15.147003Z",
     "shell.execute_reply.started": "2021-02-26T00:55:15.103654Z"
    }
   },
   "outputs": [],
   "source": [
    "features_with_outcomes = pd.merge(combined, outcome_df, on=\"IP_PATIENT_ID\", how=\"inner\")\n",
    "features_with_outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fill in Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: mean should be done on the training set\n",
    "features_with_outcomes['AGE'].fillna(features_with_outcomes['AGE'].mean(), inplace=True)\n",
    "features_with_outcomes['TOBACCO_PAK_PER_DY'].fillna(0, inplace=True)\n",
    "features_with_outcomes['TOBACCO_USED_YEARS'].fillna(0, inplace=True)\n",
    "features_with_outcomes['TOBACCO_USER'].fillna('Never', inplace=True)\n",
    "features_with_outcomes['ALCOHOL_USER'].fillna('No', inplace=True)\n",
    "features_with_outcomes['ALCOHOL_OZ_PER_WK'].fillna(0, inplace=True)\n",
    "features_with_outcomes['ILLICIT_DRUG_FREQ'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert ALCOHOL_OZ_PER_WK to numeric\n",
    "def alc_freq_to_numeric(x):\n",
    "    if x == \"0\":\n",
    "        return 0\n",
    "    if x == \"3.6 - 4.2\":\n",
    "        return 3.9\n",
    "    if x == \".6\":\n",
    "        return .6\n",
    "    if x == \"3.6\":\n",
    "        return 3.6\n",
    "    if x == \"1.8 - 3\":\n",
    "        return 2.4\n",
    "    if x == \"1.8\":\n",
    "        return 1.8\n",
    "    if x == \"2.4\":\n",
    "        return 2.4\n",
    "    if x == \"6\":\n",
    "        return 6\n",
    "    if x == \"8.4\":\n",
    "        return 8.4\n",
    "    if x == \".6 - 1.2\":\n",
    "        return 0.8\n",
    "    if x == \"12.6\":\n",
    "        return 0.0\n",
    "    if x == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        raise ValueError(\"Invalid entry: {}\".format(x))\n",
    "features_with_outcomes['ALCOHOL_OZ_PER_WK'] = features_with_outcomes['ALCOHOL_OZ_PER_WK'].apply(alc_freq_to_numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "cat_features = features_with_outcomes[['GENDER', 'RACE', \n",
    "                                      'ETHNICITY', 'PCP_PROVIDER_TYPE',\n",
    "                                      'TOBACCO_USER',\n",
    "                                      'CIGARETTES_YN',\n",
    "                                      'SMOKING_TOB_STATUS',\n",
    "                                      'ALCOHOL_USER',\n",
    "                                      'ALCOHOL_TYPE',\n",
    "                                      'IV_DRUG_USER_YN', 'ALLERGEN_ID']].to_numpy()\n",
    "OH_features = enc.fit_transform(cat_features).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#enc.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(OH_features[:,0]), sum(OH_features[:,1]), sum(OH_features[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OH_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Feature Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_features = features_with_outcomes[['AGE', 'TOBACCO_PAK_PER_DY', 'TOBACCO_USED_YEARS', 'ALCOHOL_OZ_PER_WK',\n",
    "                                   'ILLICIT_DRUG_FREQ']].to_numpy()\n",
    "real_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.concatenate((OH_features, real_features), axis=1)\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = features_with_outcomes['recommend_dialysis'].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Models (using CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: split by patient id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aucrocs = []\n",
    "accs = []\n",
    "f1_scores = []\n",
    "for train_index, test_index in skf.split(features, targets):\n",
    "    X_train, X_test = features[train_index], features[test_index]\n",
    "    y_train, y_test = targets[train_index], targets[test_index]\n",
    "\n",
    "    #clf = LogisticRegression()\n",
    "    #clf = SVC(probability=True)\n",
    "    #clf = DecisionTreeClassifier()\n",
    "    #clf = RandomForestClassifier()\n",
    "    #clf = KNeighborsClassifier(3)\n",
    "    #clf = MLPClassifier(alpha=1, max_iter=1000)\n",
    "    #clf = GaussianNB()\n",
    "    clf = MultinomialNB()\n",
    "    #clf = AdaBoostClassifier()\n",
    "    #clf = QuadraticDiscriminantAnalysis()\n",
    "    #clf = GaussianProcessClassifier(1.0 * RBF(1.0))\n",
    "    clf.fit(X_train, y_train)\n",
    "    pred_probs = clf.predict_proba(X_test)[:,1]\n",
    "    aucroc = roc_auc_score(y_test, pred_probs)\n",
    "    acc = accuracy_score(y_test, np.round(pred_probs))\n",
    "    f1_score_ = f1_score(y_test, np.round(pred_probs))\n",
    "    print(\"aucroc: {}, acc: {}, f1_score: {}\".format(aucroc, acc, f1_score_))\n",
    "    aucrocs.append(aucroc)\n",
    "    accs.append(acc)\n",
    "    f1_scores.append(f1_score_)\n",
    "print(\"mean -- aucroc: {}, acc: {}, f1_score: {}\".format(np.mean(aucrocs), np.mean(accs), np.mean(f1_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
